<!DOCTYPE html><html lang="pl"><head><meta charSet="utf-8"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="description" content="Machine Learning Research is Allegro’s R&amp;D lab created to develop and apply state-of-the-art machine learning methods, helping Allegro grow and innovate with artificial intelligence. Beyond bringing AI to production, we are committed to advance the understanding of machine learning through open collaboration with the scientific community."/><title>Allegro ML Research</title><meta property="og:site_name" content="Allegro ML research"/><meta property="og:title" content="Allegro ML research"/><meta property="og:url" content="https://ml.allegro.tech"/><meta property="og:type" content="site"/><meta property="og:image" content="https://ml.allegro.tech/images/allegro-ml-research.svg"/><link rel="shortcut icon" href="favicon.ico"/><link rel="canonical" href="https://ml.allegro.tech" itemProp="url"/><link rel="preload" href="images/splash.jpg" as="image"/><meta name="next-head-count" content="12"/><link rel="preload" href="/_next/static/css/f90f7240cef95199c2b1.css" as="style"/><link rel="stylesheet" href="/_next/static/css/f90f7240cef95199c2b1.css" data-n-g=""/><link rel="preload" href="/_next/static/css/19848dfc5b03162e97be.css" as="style"/><link rel="stylesheet" href="/_next/static/css/19848dfc5b03162e97be.css" data-n-p=""/><noscript data-n-css=""></noscript><link rel="preload" href="/_next/static/chunks/webpack-af8d060cb140570bcfb2.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework-0441fae7fd130f37dee1.js" as="script"/><link rel="preload" href="/_next/static/chunks/main-547dee26f92077ae29b6.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-789ec92d9bd7cfd0c310.js" as="script"/><link rel="preload" href="/_next/static/chunks/1bfc9850-b36c3444c0662e0df878.js" as="script"/><link rel="preload" href="/_next/static/chunks/111-1b6a593163529b0806ae.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/index-9a2b191d0eeeadf48ff5.js" as="script"/></head><body><div id="__next"><header class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card Header_navbar__2vWRp m-color-bg_card"><nav class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-display-flex m-flex-justify-between m-flex-items-center"><a href="/"><img src="images/allegro-ml-research.svg" alt="Allegro ML Research" height="45"/></a><div><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0 m-display-flex@lg m-display-none"><li class="m-margin-left-16@lg"><a href="#teams" class="m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-white-space_nowrap m-cursor_pointer m-overflow_hidden  m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-link--signal">Our projects</a></li><li class="m-margin-left-16@lg"><a href="#presentations" class="m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-white-space_nowrap m-cursor_pointer m-overflow_hidden  m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-link--signal">Talks</a></li><li class="m-margin-left-16@lg"><a href="#open-source" class="m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-white-space_nowrap m-cursor_pointer m-overflow_hidden  m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-link--signal">Open Source</a></li><li class="m-margin-left-16@lg"><a href="#publications" class="m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-white-space_nowrap m-cursor_pointer m-overflow_hidden  m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-link--signal">Publications</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://praca.allegro.pl" target="_blank">Jobs</a></li></ul><button class="m-display-none@lg m-height_40 m-line-height_40 m-border-style-top_none m-border-style-right_none m-border-style-bottom_none m-border-style-left_none m-border-radius-top-left_2 m-border-radius-top-right_2 m-border-radius-bottom-left_2 m-border-radius-bottom-right_2 m-cursor_pointer m-overflow_hidden m-appearance_none m-padding-left_4 m-padding-right_4 m-padding-top_4 m-padding-bottom_4 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button" style="background:transparent" aria-label="Otwórz menu"><img src="https://assets.allegrostatic.com/metrum/icon/menu-23e046bf68.svg" alt="" class="m-icon" width="32" height="32"/></button></div></nav></header><div class="Header_hero__n5PN5"><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-display-flex m-flex-column m-flex-justify-end m-padding-bottom_24  Header_image__15JNc"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-color-bg_desk m-color-bg_card m-width-max_768"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text  m-font-weight_100 m-font-size_32 m-font-size_43_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125">About us</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Machine Learning Research is Allegro’s R&amp;D lab created to develop and apply state-of-the-art machine learning methods, helping Allegro grow and innovate with artificial intelligence. Beyond bringing AI to production, we are committed to advance the understanding of machine learning through open collaboration with the scientific community. </p></div></div></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24" id="teams">Teams</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--4@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:1;min-height:1em;overflow:hidden"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M32,224H64V416H32A31.96166,31.96166,0,0,1,0,384V256A31.96166,31.96166,0,0,1,32,224Zm512-48V448a64.06328,64.06328,0,0,1-64,64H160a64.06328,64.06328,0,0,1-64-64V176a79.974,79.974,0,0,1,80-80H288V32a32,32,0,0,1,64,0V96H464A79.974,79.974,0,0,1,544,176ZM264,256a40,40,0,1,0-40,40A39.997,39.997,0,0,0,264,256Zm-8,128H192v32h64Zm96,0H288v32h64ZM456,256a40,40,0,1,0-40,40A39.997,39.997,0,0,0,456,256Zm-8,128H384v32h64ZM640,256V384a31.96166,31.96166,0,0,1-32,32H576V224h32A31.96166,31.96166,0,0,1,640,256Z"></path></svg> <!-- -->CX Robots</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>We focus on using NLP models to understand and automate the communication at Allegro, e.g. automatically answer questions asked to our customer support. Our main research directions are related to pretraining and evaluating large language models, semi-supervised clustering, and human-in-the-loop NLP.</p></p></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--4@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:1;min-height:1em;overflow:hidden"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M80 368H16a16 16 0 0 0-16 16v64a16 16 0 0 0 16 16h64a16 16 0 0 0 16-16v-64a16 16 0 0 0-16-16zm0-320H16A16 16 0 0 0 0 64v64a16 16 0 0 0 16 16h64a16 16 0 0 0 16-16V64a16 16 0 0 0-16-16zm0 160H16a16 16 0 0 0-16 16v64a16 16 0 0 0 16 16h64a16 16 0 0 0 16-16v-64a16 16 0 0 0-16-16zm416 176H176a16 16 0 0 0-16 16v32a16 16 0 0 0 16 16h320a16 16 0 0 0 16-16v-32a16 16 0 0 0-16-16zm0-320H176a16 16 0 0 0-16 16v32a16 16 0 0 0 16 16h320a16 16 0 0 0 16-16V80a16 16 0 0 0-16-16zm0 160H176a16 16 0 0 0-16 16v32a16 16 0 0 0 16 16h320a16 16 0 0 0 16-16v-32a16 16 0 0 0-16-16z"></path></svg> <!-- -->Learning to Rank</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>In Learning to Rank, our goal is to develop ranking models which find the optimal ordering of items for a given search results list, based on past users’ interactions. Such models constitute the final stage of Allegro’s search engine, serving millions of searches a day.</p>
<p>Some of the research problems we tackle are:</p>
<ol>
<li>Incorporation of multimodal data (textual, visual, tabular) into an end-to-end ranking model.</li>
<li>Search engine personalization</li>
<li>Developing novel ranking architectures and loss functions</li>
</ol></p></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--4@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:1;min-height:1em;overflow:hidden"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M480 416v16c0 26.51-21.49 48-48 48H48c-26.51 0-48-21.49-48-48V176c0-26.51 21.49-48 48-48h16v208c0 44.112 35.888 80 80 80h336zm96-80V80c0-26.51-21.49-48-48-48H144c-26.51 0-48 21.49-48 48v256c0 26.51 21.49 48 48 48h384c26.51 0 48-21.49 48-48zM256 128c0 26.51-21.49 48-48 48s-48-21.49-48-48 21.49-48 48-48 48 21.49 48 48zm-96 144l55.515-55.515c4.686-4.686 12.284-4.686 16.971 0L272 256l135.515-135.515c4.686-4.686 12.284-4.686 16.971 0L512 208v112H160v-48z"></path></svg> <!-- -->Visual Search</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>In Visual Search, we create machine learning models which enable us to create image embeddings suitable for similarity search. The main challenge is to make these embeddings sensitive to relevant visual traits of products like category, style, colour, pattern etc. while maintaining insensitivity to irrelevant information such as background, presence of a model, different camera angles etc.</p></p></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--4@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:1;min-height:1em;overflow:hidden"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M352 160v-32C352 57.42 294.579 0 224 0 153.42 0 96 57.42 96 128v32H0v272c0 44.183 35.817 80 80 80h288c44.183 0 80-35.817 80-80V160h-96zm-192-32c0-35.29 28.71-64 64-64s64 28.71 64 64v32H160v-32zm160 120c-13.255 0-24-10.745-24-24s10.745-24 24-24 24 10.745 24 24-10.745 24-24 24zm-192 0c-13.255 0-24-10.745-24-24s10.745-24 24-24 24 10.745 24 24-10.745 24-24 24z"></path></svg> <!-- -->PCS Automation</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>We employ a diverse set of machine learning techniques to improve the product-based experience on Allegro. Problems that we solve include, e.g., product matching i.e., being able to infer the product being sold for a merchant-created offer, or automatic integration of product definitions from external product catalogs. Examples of our research directions include sampling methods in similarity learning or extreme classification methods.</p></p></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--4@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:1;min-height:1em;overflow:hidden"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M128 352H32c-17.67 0-32 14.33-32 32v96c0 17.67 14.33 32 32 32h96c17.67 0 32-14.33 32-32v-96c0-17.67-14.33-32-32-32zm-24-80h192v48h48v-48h192v48h48v-57.59c0-21.17-17.23-38.41-38.41-38.41H344v-64h40c17.67 0 32-14.33 32-32V32c0-17.67-14.33-32-32-32H256c-17.67 0-32 14.33-32 32v96c0 17.67 14.33 32 32 32h40v64H94.41C73.23 224 56 241.23 56 262.41V320h48v-48zm264 80h-96c-17.67 0-32 14.33-32 32v96c0 17.67 14.33 32 32 32h96c17.67 0 32-14.33 32-32v-96c0-17.67-14.33-32-32-32zm240 0h-96c-17.67 0-32 14.33-32 32v96c0 17.67 14.33 32 32 32h96c17.67 0 32-14.33 32-32v-96c0-17.67-14.33-32-32-32z"></path></svg> <!-- -->Recommendations</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>The main purpose of our team is to address users’ needs, show them a broad range of products they would be interested in - thus serving as an inspiration and connecting them with useful, contextual offers.
We ground our algorithms on previous collective behaviors of our user-base. But we also work towards incorporating content features of the items into the models. Our main challenges include building novel algorithms that can give good recommendations for our users and also operate at scale. Both being a significant endeavour, considering the sheer amount of traffic Allegro serves daily.</p>
<p>We focus our research on:</p>
<ol>
<li>Building item representation, that can serve as retrieval basis,</li>
<li>Improving ways to detect user intents in clear (and useful) way,</li>
<li>Current trends in recommender systems.</li>
</ol></p></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--4@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:1;min-height:1em;overflow:hidden"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M216 288h-48c-8.84 0-16 7.16-16 16v192c0 8.84 7.16 16 16 16h48c8.84 0 16-7.16 16-16V304c0-8.84-7.16-16-16-16zM88 384H40c-8.84 0-16 7.16-16 16v96c0 8.84 7.16 16 16 16h48c8.84 0 16-7.16 16-16v-96c0-8.84-7.16-16-16-16zm256-192h-48c-8.84 0-16 7.16-16 16v288c0 8.84 7.16 16 16 16h48c8.84 0 16-7.16 16-16V208c0-8.84-7.16-16-16-16zm128-96h-48c-8.84 0-16 7.16-16 16v384c0 8.84 7.16 16 16 16h48c8.84 0 16-7.16 16-16V112c0-8.84-7.16-16-16-16zM600 0h-48c-8.84 0-16 7.16-16 16v480c0 8.84 7.16 16 16 16h48c8.84 0 16-7.16 16-16V16c0-8.84-7.16-16-16-16z"></path></svg> <!-- -->Reinforcement Learning</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>We aim to enhance various Allegro projects with exploratory algorithms, which are capable to not only exploit historical data but explore via interactions with the world. Currently, we are working on the optimization of Search Engine Marketing (SEM) and Content Optimization projects. Our main research directions include contextual bandits, A/B testing alternatives with casual impact discovery and offline RL.</p></p></div></article></div></div></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24" id="presentations">Talks</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://vimeo.com/471413175" title="Polacy nie gęsi, iż swojego BERTa mają"><img src="images/video-headers/polacy_nie_gesi.png" alt="Polacy nie gęsi, iż swojego BERTa mają" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://vimeo.com/471413175" title="Polacy nie gęsi, iż swojego BERTa mają" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-font-size_19 m-font-size_21_sm m-margin-bottom_8" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Polacy nie gęsi, iż swojego BERTa mają</h2></a><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">Piotr Rybak</p><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>An introduction to our HerBERT model. Presentation at https://www.nlpday.pl/</p></p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://vimeo.com/471413175">Watch</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://www.youtube.com/watch?v=gWDSdJfP7gU" title="Jak skutecznie zarządzać projektami uczenia maszynowego?"><img src="images/video-headers/irek_gawlik_mgmt.png" alt="Jak skutecznie zarządzać projektami uczenia maszynowego?" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://www.youtube.com/watch?v=gWDSdJfP7gU" title="Jak skutecznie zarządzać projektami uczenia maszynowego?" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-font-size_19 m-font-size_21_sm m-margin-bottom_8" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Jak skutecznie zarządzać projektami uczenia maszynowego?</h2></a><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">Ireneusz Gawlik</p><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>Presentation at https://ghostday.pl/</p></p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.youtube.com/watch?v=gWDSdJfP7gU">Watch</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://www.youtube.com/watch?v=vSSZ3ANyVb0" title="What does the user ask for? - Discovering new intents in conversational data"><img src="images/video-headers/p.rybak_intencje.png" alt="What does the user ask for? - Discovering new intents in conversational data" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://www.youtube.com/watch?v=vSSZ3ANyVb0" title="What does the user ask for? - Discovering new intents in conversational data" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-font-size_19 m-font-size_21_sm m-margin-bottom_8" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">What does the user ask for? - Discovering new intents in conversational data</h2></a><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">Piotr Rybak</p><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>Presentation at https://ghostday.pl/index.php/speakers/#talk-613</p></p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.youtube.com/watch?v=vSSZ3ANyVb0">Watch</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://www.youtube.com/watch?v=tC3yNlPg_Bw" title="Challenges of commercializing language models on mobile devices"><img src="images/video-headers/sz.lecki_prod.png" alt="Challenges of commercializing language models on mobile devices" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://www.youtube.com/watch?v=tC3yNlPg_Bw" title="Challenges of commercializing language models on mobile devices" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-font-size_19 m-font-size_21_sm m-margin-bottom_8" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Challenges of commercializing language models on mobile devices</h2></a><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">Szymon Łęski</p><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>Presentation at https://ghostday.pl/index.php/speakers/#talk-664</p></p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.youtube.com/watch?v=tC3yNlPg_Bw">Watch</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://www.youtube.com/watch?v=wsBLHArYFtM" title="Batch construction strategies in deep metric learning"><img src="images/video-headers/kalina_batch_const.png" alt="Batch construction strategies in deep metric learning" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://www.youtube.com/watch?v=wsBLHArYFtM" title="Batch construction strategies in deep metric learning" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-font-size_19 m-font-size_21_sm m-margin-bottom_8" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Batch construction strategies in deep metric learning</h2></a><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">Bartosz Ludwiczuk &amp; Kalina Kobus</p><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>Presentation at https://ghostday.pl/index.php/speakers/#talk-615</p></p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.youtube.com/watch?v=wsBLHArYFtM">Watch</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://www.youtube.com/watch?v=hXGSxTNVmwg" title="(Many shades of) ML @ Allegro.pl: NLP, Vision &amp; ranking at the largest Polish e-commerce marketplace"><img src="images/video-headers/przemoc_many_shades.png" alt="(Many shades of) ML @ Allegro.pl: NLP, Vision &amp; ranking at the largest Polish e-commerce marketplace" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://www.youtube.com/watch?v=hXGSxTNVmwg" title="(Many shades of) ML @ Allegro.pl: NLP, Vision &amp; ranking at the largest Polish e-commerce marketplace" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-font-size_19 m-font-size_21_sm m-margin-bottom_8" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">(Many shades of) ML @ Allegro.pl: NLP, Vision &amp; ranking at the largest Polish e-commerce marketplace</h2></a><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">Przemysław Pobrotyn</p><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>Presentation at https://ghostday.pl/index.php/speakers/#talk-706</p></p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.youtube.com/watch?v=hXGSxTNVmwg">Watch</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://www.youtube.com/watch?v=UT3bGUEY-8o" title="Machine learning i przyszłość algorytmów"><img src="images/video-headers/irek.gawlik_copernicus.png" alt="Machine learning i przyszłość algorytmów" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://www.youtube.com/watch?v=UT3bGUEY-8o" title="Machine learning i przyszłość algorytmów" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-font-size_19 m-font-size_21_sm m-margin-bottom_8" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Machine learning i przyszłość algorytmów</h2></a><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">Ireneusz Gawlik</p><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>Presentation at <a href="https://copernicusfestival.com/event/machine-learning-i-przyszlosc-algorytmow-czy-sztuczna-inteligencja-moze-zrozumiec-zachowania-konsumentow/">Copernicus Festival</a></p></p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.youtube.com/watch?v=UT3bGUEY-8o">Watch</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://allegro.tech/podcast/badania_i_rozwoj_ml_w_allegro/" title="Badania i rozwój ML w Allegro"><img src="images/video-headers/irek.gawlik_podcast.png" alt="Badania i rozwój ML w Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://allegro.tech/podcast/badania_i_rozwoj_ml_w_allegro/" title="Badania i rozwój ML w Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-font-size_19 m-font-size_21_sm m-margin-bottom_8" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Badania i rozwój ML w Allegro</h2></a><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">Ireneusz Gawlik</p><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>Allegro.tech podcast</p></p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://allegro.tech/podcast/badania_i_rozwoj_ml_w_allegro/">Watch</a></div></article></div></div></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24" id="open-source">Open-Source</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--4@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://github.com/allegro/allRank" title="allRank" class="m-text-decoration_none m-border-style-bottom_solid m-border-width_1 m-border-color_gray"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:1;min-height:1em;overflow:hidden"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M384 320H256c-17.67 0-32 14.33-32 32v128c0 17.67 14.33 32 32 32h128c17.67 0 32-14.33 32-32V352c0-17.67-14.33-32-32-32zM192 32c0-17.67-14.33-32-32-32H32C14.33 0 0 14.33 0 32v128c0 17.67 14.33 32 32 32h95.72l73.16 128.04C211.98 300.98 232.4 288 256 288h.28L192 175.51V128h224V64H192V32zM608 0H480c-17.67 0-32 14.33-32 32v128c0 17.67 14.33 32 32 32h128c17.67 0 32-14.33 32-32V32c0-17.67-14.33-32-32-32z"></path></svg> <!-- -->allRank</h2></a><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>framework for training neural Learning-to-Rank (LTR) models,
featuring implementations of:</p>
<ul>
<li>common pointwise, pairwise and listwise loss function,</li>
<li>fully connected and Transformer-like scoring function,</li>
<li>commonly used evaluation metrics like Normalized Discounted Cumulative Gain (NDCG) and Mean Reciprocal Rank (MRR},</li>
<li>click-models for experiments on simulated click-through data</li>
</ul></p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://github.com/allegro/allRank">Try it!</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--4@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://klejbenchmark.com/" title="KLEJ Benchmark" class="m-text-decoration_none m-border-style-bottom_solid m-border-width_1 m-border-color_gray"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:1;min-height:1em;overflow:hidden"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 352 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M205.22 22.09c-7.94-28.78-49.44-30.12-58.44 0C100.01 179.85 0 222.72 0 333.91 0 432.35 78.72 512 176 512s176-79.65 176-178.09c0-111.75-99.79-153.34-146.78-311.82zM176 448c-61.75 0-112-50.25-112-112 0-8.84 7.16-16 16-16s16 7.16 16 16c0 44.11 35.89 80 80 80 8.84 0 16 7.16 16 16s-7.16 16-16 16z"></path></svg> <!-- -->KLEJ Benchmark</h2></a><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>The KLEJ benchmark (Kompleksowa Lista Ewaluacji Językowych) is a set of nine evaluation tasks for the Polish language understanding. Key benchmark features:</p>
<ul>
<li>It contains a diverse set of tasks from different domains and with different objectives,</li>
<li>Most tasks are created from existing datasets but we also release the new sentiment analysis dataset from an e-commerce domain.</li>
</ul></p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://klejbenchmark.com/">Try it!</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--4@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://huggingface.co/allegro" title="HerBERT" class="m-text-decoration_none m-border-style-bottom_solid m-border-width_1 m-border-color_gray"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:1;min-height:1em;overflow:hidden"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M384 320H256c-17.67 0-32 14.33-32 32v128c0 17.67 14.33 32 32 32h128c17.67 0 32-14.33 32-32V352c0-17.67-14.33-32-32-32zM192 32c0-17.67-14.33-32-32-32H32C14.33 0 0 14.33 0 32v128c0 17.67 14.33 32 32 32h95.72l73.16 128.04C211.98 300.98 232.4 288 256 288h.28L192 175.51V128h224V64H192V32zM608 0H480c-17.67 0-32 14.33-32 32v128c0 17.67 14.33 32 32 32h128c17.67 0 32-14.33 32-32V32c0-17.67-14.33-32-32-32z"></path></svg> <!-- -->HerBERT</h2></a><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1"><p>HerBERT is a BERT-based language model trained on six different corpora for Polish language understanding. It achieves state-of-the-art results on multiple downstream tasks, including <a href="https://klejbenchmark.com/">KLEJ Benchmark</a> and Part-of-Speech tagging. We release both Base and Large variants of the model as a part of <a href="https://github.com/huggingface/transformers">transformers</a> library for anyone to use.</p></p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://huggingface.co/allegro">Try it!</a></div></article></div></div></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24" id="publications">Publications</h2><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto"><div class="m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-padding-bottom-0 m-padding-top-0 m-color-bg_card"><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-color-gray">2021</p><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-font-size_19 m-font-size_21_sm m-margin-bottom_8 m-margin-bottom_0_sm m-flex-grow_1">Subgoal Search For Complex Reasoning Tasks</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Authors: <!-- -->Konrad Czechowski, Tomasz Odrzygóźdź, Marek Zbysiński, Michał Zawalski, Krzysztof Olejnik, Yuhuai Wu, Łukasz Kuciński, Piotr Miłoś</p><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Accepted at: <!-- -->Conference and Workshop on Neural Information Processing Systems (NeurIPS)</p></article><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://arxiv.org/abs/2108.11204">Read</a></div><div class="m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-padding-bottom-0 m-padding-top-0 m-color-bg_card"><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-color-gray">2021</p><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-font-size_19 m-font-size_21_sm m-margin-bottom_8 m-margin-bottom_0_sm m-flex-grow_1">HerBERT: Efficiently Pretrained Transformer-based Language Model for Polish</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Authors: <!-- -->Robert Mroczkowski, Piotr Rybak, Alina Wróblewska, Ireneusz Gawlik</p><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Accepted at: <!-- -->BSNLP, accepted long paper</p></article><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.aclweb.org/anthology/2021.bsnlp-1.1/">Read</a></div><div class="m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-padding-bottom-0 m-padding-top-0 m-color-bg_card"><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-color-gray">2020</p><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-font-size_19 m-font-size_21_sm m-margin-bottom_8 m-margin-bottom_0_sm m-flex-grow_1">KLEJ: Comprehensive Benchmark for Polish Language Understanding</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Authors: <!-- -->Piotr Rybak, Robert Mroczkowski, Janusz Tracz, Ireneusz Gawlik</p><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Accepted at: <!-- -->ACL 2020, accepted long paper</p></article><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.aclweb.org/anthology/2020.acl-main.111/">Read</a></div><div class="m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-padding-bottom-0 m-padding-top-0 m-color-bg_card"><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-color-gray">2020</p><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-font-size_19 m-font-size_21_sm m-margin-bottom_8 m-margin-bottom_0_sm m-flex-grow_1">Context-Aware Learning to Rank with Self-Attention</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Authors: <!-- -->Przemysław Pobrotyn, Tomasz Bartczak, Mikołaj Synowiec, Radosław Białobrzeski, Jarosław Bojar</p><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Accepted at: <!-- -->SIGIR eCommerce Workshop 2020, contributed talk</p></article><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://arxiv.org/abs/2005.10084">Read</a></div><div class="m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-padding-bottom-0 m-padding-top-0 m-color-bg_card"><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-color-gray">2020</p><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-font-size_19 m-font-size_21_sm m-margin-bottom_8 m-margin-bottom_0_sm m-flex-grow_1">NeuralNDCG: Direct Optimisation of a Ranking Metric via Differentiable Relaxation of Sorting</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Authors: <!-- -->Przemysław Pobrotyn, Radosław Białobrzeski</p><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Accepted at: <!-- -->The 2021 SIGIR Workshop On eCommerce (SIGIR eCom ’21)</p></article><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://arxiv.org/abs/2102.07831">Read</a></div><div class="m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-padding-bottom-0 m-padding-top-0 m-color-bg_card"><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-color-gray">2020</p><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-font-size_19 m-font-size_21_sm m-margin-bottom_8 m-margin-bottom_0_sm m-flex-grow_1">BERT-based similarity learning for product matching</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Authors: <!-- -->Janusz Tracz, Piotr Wójcik, Kalina Jasinska-Kobus, Riccardo Belluzzo, Robert Mroczkowski, Ireneusz Gawlik</p><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Accepted at: <!-- -->EComNLP 2020 COLING Workshop on Natural Language Processing in E-Commerce</p></article><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.aclweb.org/anthology/2020.ecomnlp-1.7/">Read</a></div></div></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Job offers</h2><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto"><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Kraków, Poznań, Toruń, Wrocław</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999778992282-research-engineer-machine-learning?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Apply</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning (Ranking and Recommendations)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Poznań, Kraków, Toruń, Wrocław</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999777750483-research-engineer-machine-learning-ranking-and-recommendations?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Apply</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning (Reinforcement Learning)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Kraków, Poznań, Toruń</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999777595922-research-engineer-machine-learning-reinforcement-learning?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Apply</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning (Computer Vision)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Kraków, Poznań, Toruń</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999777595727-research-engineer-machine-learning-computer-vision?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Apply</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Data Scientist (Allegro Pay)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999777595496-data-scientist-allegro-pay?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Apply</a></article></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://allegro.pl/praca">See more job offers</a></div><footer class="m-color-bg_navy m-margin-top-32"><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24 m-padding-bottom-24 m-display-flex@sm m-flex-justify-between m-flex-items-center m-text-align_center"><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-color_white m-padding-left-24@sm">Proudly built by Allegro Tech engineers</p><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0 m-display-flex m-flex-justify-center"><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://github.com/allegro"><img src="https://assets.allegrostatic.com/metrum/icon/github-6a18df1729.svg" alt="Github" class="m-icon"/></a></li><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://www.facebook.com/allegro.tech/"><img src="https://assets.allegrostatic.com/metrum/icon/facebook-a2b92f9dcb.svg" alt="Facebook" class="m-icon"/></a></li><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/allegrotech"><img src="https://assets.allegrostatic.com/metrum/icon/twitter-25164a58aa.svg" alt="Twitter" class="m-icon"/></a></li></ul></div></footer><div style="visibility:hidden;height:0;overflow:hidden;position:relative"><img alt="doubleclick" width="1" height="1" style="position:absolute" src="https://pubads.g.doubleclick.net/activity;dc_iu=/21612525419/DFPAudiencePixel;ord=3641089824055.137;dc_seg=507368552?"/><img alt="fb" height="1" width="1" style="position:absolute" src="https://www.facebook.com/tr?id=1650870088530325&amp;ev=PageView&amp;noscript=1"/></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"How to ruin your Elasticsearch performance — Part II: Breaking things, one at a time","link":"https://blog.allegro.tech/2021/10/how-to-ruin-elasticsearch-performance-part-ii.html","pubDate":"Thu, 07 Oct 2021 00:00:00 +0200","authors":{"author":[{"name":["Michał Kosmulski"],"photo":["https://blog.allegro.tech/img/authors/michal.kosmulski.jpg"],"url":["https://blog.allegro.tech/authors/michal.kosmulski"]}]},"content":"\u003cp\u003eIt’s easy to find resources about \u003cem\u003eimproving\u003c/em\u003e \u003ca href=\"https://www.elastic.co/elastic-stack\"\u003eElasticsearch\u003c/a\u003e performance, but what if you wanted to \u003cem\u003ereduce\u003c/em\u003e it?\nIn \u003ca href=\"/2021/09/how-to-ruin-elasticsearch-performance-part-i.html\"\u003ePart I\u003c/a\u003e of this two-part series we looked under the hood in order to learn how\nES works internally. Now, in Part II, is the time to apply this knowledge in practice and ruin our ES performance. Most tips should also be applicable to\n\u003ca href=\"https://solr.apache.org/\"\u003eSolr\u003c/a\u003e, raw \u003ca href=\"https://lucene.apache.org/\"\u003eLucene\u003c/a\u003e, or, for that matter, to any other full-text search engine as well.\u003c/p\u003e\n\n\u003ch2 id=\"using-complex-boolean-queries\"\u003eUsing complex boolean queries\u003c/h2\u003e\n\n\u003cp\u003eA consequence of the algorithms outlined in \u003ca href=\"/2021/09/how-to-ruin-elasticsearch-performance-part-i.html\"\u003ePart I\u003c/a\u003e is that simple queries, such as finding\na document containing two or three specific words, are relatively cheap to compute. We can easily increase the cost by making the queries more complex. This\ncomplexity is easily achieved by using \u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/6.8/query-dsl-bool-query.html\"\u003eboolean queries\u003c/a\u003e which allow\narbitrary boolean expressions, including nested subexpressions.\u003c/p\u003e\n\n\u003cp\u003eA “flat” query, even with many words, boils down to a single AND/OR operation (though potentially with many lists). Since a search engine is usually\nsmart enough to sort these lists by length, it can execute such queries really fast. But what happens if we use a complex boolean expression? Let’s compare\ntwo example queries:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eQ1: find books which contain all of the words: “I like apples”\u003c/li\u003e\n  \u003cli\u003eQ2: find books which contain all of the words: “I like apples” or “I like oranges” and were published in 2020 or 2021 and are at least 100 pages long\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eLet us now look at the boolean expressions which correspond to these queries:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eQ1: \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eI AND like AND apples\u003c/code\u003e\u003c/li\u003e\n  \u003cli\u003eQ2: \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e((I AND like AND apples) OR (I AND like AND oranges)) AND (2020 OR 2021) AND (pages \u0026gt;= 100)\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eClearly, there is much more stuff to compute in the case of Q2, and the query will take more time, accordingly. Even though from the end user’s perspective,\nwe only added a few filters, the complexity of the query rose dramatically. For Q1, we need to perform 2 AND operations. For Q2, we end up with\n6 AND operations and 2 OR operations. However, this query is probably still much worse for performance than it may seem.\u003c/p\u003e\n\n\u003cp\u003eLet’s start analyzing this query from the bottom up.\u003c/p\u003e\n\n\u003cp\u003eThe expression \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e2020 OR 2021\u003c/code\u003e is a little gem that looks innocent, but is actually quite expensive. As you remember, the cost of an OR operation is proportional\nto the sum of the sizes of input lists. The lists of books published in a year are probably quite long, so the cost of merging two will be quite high.\nAs a bonus, we get an even longer list as a result and this long list will take part in any computations that follow. So here are the takeaways:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eOR operations are costly,\u003c/li\u003e\n  \u003cli\u003eeven more so when inputs are large document sets;\u003c/li\u003e\n  \u003cli\u003esubqueries (parentheses in the logical expression) cause temporary postings lists to be created, which then take part in further calculations and so their\nsizes affect query performance.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eLooking further at our query, we see that even more temporary document ID lists will have to be created: one for each pair of parentheses. These results have\nto be computed, and since they are temporary partial results, they will have to be stored in memory since they cannot be retrieved from the index directly.\u003c/p\u003e\n\n\u003cp\u003eAlso note that subqueries can hinder many optimizations search engines employ. I mentioned earlier that Lucene sorts postings lists by length when AND-ing\nthem together. This can only work reliably if list lengths are known. For a postings list of a single word, its length is stored in the index and known exactly\nup-front. For a nested subexpression, however, the number of matches is not known before the subexpression is evaluated. But, Lucene needs the number of matches\nin order to prepare the optimal query plan. This leads to a chicken-and-egg problem which Lucene solves by estimating the size of subquery results list based\non the sizes of its constituents. For example, it estimates the result size of a subquery with OR-s as the sum of its input sizes. Being just an estimate, this\nnumber may differ from the actual value, and thus cause suboptimal query performance further up the stack. Takeaway:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003esubqueries are great at hindering global query optimizations.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAnother reason why subqueries may negatively affect performance becomes apparent with queries such as \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e(a AND b) AND (c AND d)\u003c/code\u003e. Since AND is an associative\noperation, the expression above gives the same result as \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ea AND b AND c AND d\u003c/code\u003e. In the\nversion without parentheses, the optimization of sorting lists by size works globally since all inputs are at the same nesting level, potentially achieving\nbetter performance than the version with nested subexpressions which can only sort the lists within each pair of parentheses separately.\u003c/p\u003e\n\n\u003cp\u003eYou may wonder why anyone would add these parentheses, but such constructs may arise naturally due to the way your code is structured if individual subqueries\nare built by separate methods or classes because they serve different business needs.\u003c/p\u003e\n\n\u003cp\u003eLooking at how long postings lists affect query performance, especially with OR operator, you can see one of the reasons for introducing\n\u003ca href=\"https://en.wikipedia.org/wiki/Stop_word\"\u003estopwords\u003c/a\u003e into search configuration. Words such as \u003cem\u003ethe\u003c/em\u003e are very common and on one hand they introduce practically\nno meaning at all to the query (with rare exceptions), matching almost all documents anyway, and on the other, they could add immense computational cost.\u003c/p\u003e\n\n\u003cp\u003eObviously, the longest postings list possible is the one containing all documents in the index. And indeed, pure negative queries such as\n“all documents but those with the word x” tend to be very expensive. Surprisingly, AND-ing the full set of documents (the result of a\n\u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/6.8/query-dsl-match-all-query.html\"\u003ematch_all query\u003c/a\u003e) with results of another query is very fast.\nThis is because of a \u003ca href=\"https://github.com/apache/lucene/blob/5e0e7a5479bca798ccfe385629a0ca2ba5870bc0/lucene/core/src/java/org/apache/lucene/search/BooleanQuery.java#L449\"\u003especial optimization\u003c/a\u003e\nwhich uses the identity \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eALL AND a = a\u003c/code\u003e to simplify those queries so that the expensive computation can be completely avoided.\nThis kind of query rewriting can transform a number of query patterns to queries with the same result but better performance characteristics.\nHowever, this only works for a set of rather simple cases: for example if you do not use \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ematch_all\u003c/code\u003e query, but create some other query which also happens\nto match all documents, this optimization will not be triggered. Complex query structure with subqueries can effectively disable such optimizations as well.\u003c/p\u003e\n\n\u003cp\u003eThinking about indexing and index segments, you have to notice that merging partial results from each segment is an operation similar to OR-ing (though it\nadditionally has to account for document removal and updates). This leads to the conclusion that having many segments hurts search performance, especially\nfor popular keywords whose postings lists are large to start with. Indeed, this actually happens. Performance may vary significantly depending on the number\nof segments, and the optimum is having just a single segment in your index. In Elastic, you can use the\n\u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/6.8/indices-forcemerge.html\"\u003eforce merge\u003c/a\u003e API to reduce the number of segments after indexing.\nI have actually worked with a product in which data was never indexed incrementally, but instead the whole index was rebuilt from scratch and force-merged to a single\nsegment after each update. This was a relatively small index with high search traffic, so big gains in search performance (on the order of two times shorter response\ntimes) were a justifiable reason for this seemingly wasteful indexation process.\u003c/p\u003e\n\n\u003ch2 id=\"complex-queries-in-disguise\"\u003eComplex queries in disguise\u003c/h2\u003e\n\n\u003cp\u003eSome queries seem simple, but are actually very complex for the search engine to handle. One example is prefix queries such as \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ecat*\u003c/code\u003e (which matches documents\ncontaining any words starting with \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ecat\u003c/code\u003e). It turns out that unless you do something special, such a query is likely to be handled as an OR-query with all words\nmatching the prefix: \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e(cat OR catamaran OR catapult OR category OR ...)\u003c/code\u003e. Keeping in mind that queries with the OR operator can be expensive, you see the risk:\nthere may be lots and lots of words in the resulting expression, increasing the cost of merging their corresponding postings lists. In most datasets, a query such as \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ea*\u003c/code\u003e,\nwith probably thousands of individual postings lists, each containing millions of documents, can take ages to finish and even bring down the whole cluster.\u003c/p\u003e\n\n\u003cp\u003eAnother type of query that looks simple at first glance but can (or rather, used to) be very costly is range searches in numeric and date fields. Let’s say you want to limit\nyour query to only documents modified between 2020-01-01 and 2020-12-31. How costly could that be? The inverted index maps individual values to lists of\ndocument IDs. If each value in the index corresponds to a single day, and the documents are evenly spread throughout the year, there will be 366 lists to join\nwith the OR operator. If the data is indexed with millisecond resolution, there will be many more, with performance becoming even worse.\u003c/p\u003e\n\n\u003cp\u003eFortunately, these issues have been known for a long time, and there are a number of solutions in place. For text fields, you can enable\n\u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/6.8/index-prefixes.html\"\u003eprefix indexing\u003c/a\u003e which creates special structures in the index which\ncontain merged postings lists so that they don’t have to be computed at query time. Range queries on numeric and date fields are now optimized by default\nin Elasticsearch by creating \u003ca href=\"https://lucene.apache.org/core/2_9_4/api/core/org/apache/lucene/search/NumericRangeQuery.html#precisionStepDesc\"\u003eadditional structures in the index\u003c/a\u003e\nas well, though with a particularly nasty data set, you might still be able to trigger some issues. Note that these solutions are space-time tradeoffs\n(speeding up searches at the cost of larger index), and as with any tradeoff, there is always some risk of shooting yourself in the foot. Also, new versions\nintroduce new optimizations, so \u003ca href=\"https://www.elastic.co/blog/apache-lucene-numeric-filters\"\u003ebehavior may well change between ES versions\u003c/a\u003e.\nInterestingly, some preconceptions related to performance are very persistent (not only in the full-text search field), and you may run into people\nrecommending optimizations which made sense ten years ago, but may be counterproductive now. For example,\n\u003ca href=\"https://discuss.elastic.co/t/efficient-date-range-handling/3465\"\u003erange searches have been efficient for ten years\u003c/a\u003e, and apart from extreme cases, you should\nnot need to worry about them too much now.\u003c/p\u003e\n\n\u003cp\u003eAs a side note, ES tries to protect you from yourself and by default disables some types of queries that are likely to be costly: you have to\n\u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/7.x/query-dsl.html#query-dsl-allow-expensive-queries\"\u003eexplicitly enable them\u003c/a\u003e if you know what\nyou’re doing and want to use them.\u003c/p\u003e\n\n\u003ch2 id=\"returning-lots-of-search-results\"\u003eReturning lots of search results\u003c/h2\u003e\n\n\u003cp\u003eElasticsearch indexes may be huge, often searching millions and billions of documents, but usually only a tiny fraction of these documents match each query’s\ncriteria, and out of those, only a handful (10 or so) are returned to the end user. Increasing the number of documents returned is detrimental to search performance\nin many ways:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eSome algorithms, such as \u003ca href=\"https://en.wikipedia.org/wiki/Partial_sorting\"\u003efinding the top N results\u003c/a\u003e when sorting, have complexity which depends on N:\nthey are faster if N is much smaller than the total number of matches, and become slower as N grows.\u003c/li\u003e\n  \u003cli\u003eSome operations a full-text search engine performs are proportional to the number of documents returned (linear complexity). As you remember, just finding matches is very fast since it\nuses inverted indices, but in order to actually return the documents’ contents, they have to be fetched from document store, and this operation scales linearly\nwith the number of documents returned. So, if you fetch 100 documents instead of 10, this part takes around ten times longer. Same goes for highlighting\nquery terms. The amount of data transferred over the network scales similarly.\u003c/li\u003e\n  \u003cli\u003eAggregations such as grouping documents by a field’s value may also have linear complexity (the number of documents returned being the input size).\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAlso note that paging the results (e.g. retrieving 100 pages of 10 documents each instead of a single request asking for 1000 documents) helps only a little.\nThe problem is that in order to find documents on positions 991-1000, Elastic has to find the complete list of results 1-1000 first, and only then take the last\n10 items. This means the cost of fetching documents from storage is indeed proportional to 10, but the cost of performing set operations on postings lists\nand aggregations as well as memory usage is still proportional to 1000.\u003c/p\u003e\n\n\u003cp\u003eSo, if you think you can have millions of documents in ES and can just retrieve them all (or some large subset) using a simple query, you may be in for a surprise.\nThere are \u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/7.x/paginate-search-results.html\"\u003especialized APIs for such a use case\u003c/a\u003e, but they all have\ntheir limitations.\u003c/p\u003e\n\n\u003ch2 id=\"assuming-elastic-knows-as-much-about-your-data-as-you-do\"\u003eAssuming Elastic knows as much about your data as you do\u003c/h2\u003e\n\n\u003cp\u003eMuch of the discussion up to this point revolved around replacing boolean expressions with their equivalents that have different performance characteristics.\nSome of these transformations are always correct since both expressions can be proven equal by means of boolean algebra.\nHowever, sometimes two forms of a query are equivalent only within a specific data set. Despite many smart optimizations used by modern full-text search\nengines, by using knowledge about your dataset you can often achieve more in terms of increasing or decreasing search performance than by relying on\nmathematics alone.\u003c/p\u003e\n\n\u003cp\u003eA simple example of using this knowledge in practice is improving performance by removing subqueries which are redundant due to the nature of the data.\nSuppose your index contains both printed and online publications. Only online publications have a URL. By following the simplest logic, if you wanted to find\nan online publication by URL, you would issue a query such as \u003ccode class=\"language-plaintext highlighter-rouge\"\u003etype:online AND url:value\u003c/code\u003e. This will work, although you could query just \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eurl:value\u003c/code\u003e as well.\nHowever, it requires that you know something about your data, namely that only online publications have any value set in the \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eurl\u003c/code\u003e field.\nObviously, this simplified query will be faster than the original.\u003c/p\u003e\n\n\u003cp\u003eWhere you can’t avoid complex queries, you can still use your domain knowledge to improve or reduce performance. For example, since the cost of merge operations\ndepends on sizes of inputs, knowing that a particular subquery is likely to return many or few results (query selectivity) and modifying the query in a way\nin which the sizes of consecutive intermediate results diminish faster may boost performance, while relying only on Elastic’s optimizations may result in\nsub-par performance.\u003c/p\u003e\n\n\u003cp\u003eSuppose (a real-world example) there is an index with two types of documents whose counts differ wildly: documents of type 1 make up 99% of the index while\ntype 2 amounts to just 1% of all documents. Certain queries must be limited to just a single type. The obvious way to filter these results is to add a clause\nsuch as \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e... AND type:1\u003c/code\u003e and \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e... AND type:2\u003c/code\u003e, correspondingly, but replacing the first one with \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e... AND NOT type:2\u003c/code\u003e may be faster since the results list for\ntype 2 is much shorter than for type 1. If the filters can be combined (e.g. by the user checking checkboxes in a GUI), and the user selects both types,\nmeaning effectively no filtering by type, it is probably much more efficient to simply remove the filter from the query than to add a \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e... AND (type:1 OR type:2)\u003c/code\u003e\nclause.\u003c/p\u003e\n\n\u003cp\u003eAs you may have already realized, not only boolean queries’ but also range queries’ performance may depend a lot on your data, for example on a field’s\ncardinality (the number of unique values). One of the more spectacular ways of shooting yourself in the foot is applying a pattern which normally helps\nperformance, but in your particular case, due to a specific distribution of a field’s values, does just the opposite. Such situations may be very difficult\nto discover if you do not precisely track performance before and after each significant change. Sneakily placing such a pattern in your code can be a great way\nto end up with low performance difficult to explain.\u003c/p\u003e\n\n\u003cp\u003eFor a real life example, consider the rule of thumb that if you don’t care about a subquery’s score, using \u003ccode class=\"language-plaintext highlighter-rouge\"\u003efilter\u003c/code\u003e subqueries within a \u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/7.x/query-dsl-bool-query.html\"\u003ebool query\u003c/a\u003e\nresults in faster response times than using \u003ccode class=\"language-plaintext highlighter-rouge\"\u003emust\u003c/code\u003e subqueries since the former \u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/7.x/query-filter-context.html\"\u003edo not need to update matching documents’ scores\u003c/a\u003e.\nIn our advertising system, we match ads in a way mostly consistent with the way we match organic results. We match ads by keywords, but we also take\ninto account criteria such as delivery methods selected by the user. In the latter case, the fact that a sponsored offer\nis available with some delivery method only affects which offers match, but does not affect their scores. This is a perfect use case for \u003ccode class=\"language-plaintext highlighter-rouge\"\u003efilter\u003c/code\u003e queries.\nHowever, we also use \u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/7.x/query-dsl-function-score-query.html\"\u003efunction score query\u003c/a\u003e.\nFunction score query allows us to combine a document’s score resulting from how well it matches our keywords with additional factors.\nFunction score query accepts an embedded query — only documents matching this query have their scores modified. Symbolically, we could express it as our\ncomplete query being: \u003ccode class=\"language-plaintext highlighter-rouge\"\u003efunction_score_query(keyword_subquery AND filters_subquery)\u003c/code\u003e. At one point, I wanted to optimize the performance of this query, and\nfollowing the abovementioned rule of thumb, thought that it would make sense to move \u003ccode class=\"language-plaintext highlighter-rouge\"\u003efilters_subquery\u003c/code\u003e outside of \u003ccode class=\"language-plaintext highlighter-rouge\"\u003efunction_score_query\u003c/code\u003e since filters need\nnot participate in score calculations. This resulted in the query \u003ccode class=\"language-plaintext highlighter-rouge\"\u003efilters_subquery AND function_score_query(keyword_subquery)\u003c/code\u003e and should have\nimproved search performance. However, upon running performance tests, to my surprise I realized these changes actually made performance worse. The reason was,\nwith the filters moved outside \u003ccode class=\"language-plaintext highlighter-rouge\"\u003efunction_score_query\u003c/code\u003e, \u003ccode class=\"language-plaintext highlighter-rouge\"\u003efunction_score_query\u003c/code\u003e had to modify the scores of a larger number of documents and for the particular\ndata I had in my index, the added cost of rescoring more documents was greater than the savings achieved by not having to calculate the score for these\ndocuments in the first place. This just shows that with performance tuning, \u003ca href=\"https://en.wiktionary.org/wiki/your_mileage_may_vary\"\u003eYMMV\u003c/a\u003e, always.\u003c/p\u003e\n\n\u003ch2 id=\"treating-search-and-indexing-as-two-separate-problems\"\u003eTreating search and indexing as two separate problems\u003c/h2\u003e\n\n\u003cp\u003eYou might be tempted to think of Elasticsearch as yet another database. If you do, you are likely to run into many issues, including performance problems.\nOne of the main things that set ES apart from most databases, whether they be SQL or NoSQL, is the\n\u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/7.x/near-real-time.html\"\u003esearch-indexing asymmetry\u003c/a\u003e.\nIn contrast to a normal database, in Elasticsearch you can’t just insert a bunch of documents: this process triggers indexing, creates new segments, potentially\ntriggers segment merges, has to \u003ca href=\"https://www.alibabacloud.com/blog/elasticsearch-distributed-consistency-principles-analysis-3---data_594360\"\u003epropagate replicas and handle consistency within the cluster\u003c/a\u003e,\netc. This may all affect performance in interesting ways. While indices of some kind are used in pretty much all databases, in ES they play\na central role. Another important difference to databases is that Elastic data model favors, and often forces, very much denormalized data. This is\ncommon with NoSQL databases but in ES, it is even more extreme.\u003c/p\u003e\n\n\u003cp\u003eIn particular, since ES is — in most cases — more about search performance than anything else, it is a common optimization to move cost from search time to\nindexing time when possible, and many such optimizations result in an even more denormalized data model.\u003c/p\u003e\n\n\u003cp\u003eFor example, let’s consider an index of offers such as you may find in an online store. Each offer may be available with a free return option, but\nthere’s a catch: while the client only sees a single checkbox in the UI, internally there are several types of free returns, e.g. free return by package locker\nand free return by post. The natural way to handle this would be to index each of these two flags and then to search for offers having either of those flags.\nIt would also be a step towards our goal of ruining Elasticsearch search performance, especially if the number of values was 200 rather than 2.\u003c/p\u003e\n\n\u003cp\u003eThe reason it works this way is that there are lots and lots of offers matching any of these flags: probably around 90% match one and around 90% match the other\n(with, obviously, a large number matching both). Going back to the \u003ca href=\"/2021/09/how-to-ruin-elasticsearch-performance-part-i.html#or-operator\"\u003esection about OR operator\u003c/a\u003e, you will notice that having two very long\ninput lists is about the worst case for OR operator efficiency. A usually reasonable trade-off in such a case is to move the cost to indexing-time, and\nto index with the document just a single flag, “free return”, which will improve search performance (at the cost of reducing indexing performance by just a tiny amount).\nNote that this was a very simple case and sometimes indexing denormalized data may increase index size significantly, in which case the trade-off may become\nless obvious.\u003c/p\u003e\n\n\u003cp\u003eAnother quirk is the mutual interaction between indexing and search performance. Interaction between reads and writes happens in practically any database,\nbut with Elastic, it is easier for it to become an issue due to the relatively high CPU and I/O cost of indexing. Ignoring this fact and treating\nsearch and indexing performance as two independent issues is a recipe for poor performance in both areas.\u003c/p\u003e\n\n\u003ch2 id=\"jumping-right-into-optimization-without-checking-first\"\u003eJumping right into optimization without checking first\u003c/h2\u003e\n\n\u003cp\u003eOne effective method of achieving inferior performance, which works not only with Elasticsearch, is jumping\nright into optimization without first analyzing the problem, and, even better, not checking if there is a problem at all. It is a boring thing to repeat\nover and over, but the only way to improve performance is to:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003efirst, measure the baseline you are starting from (avoiding common pitfalls along the way),\u003c/li\u003e\n  \u003cli\u003edecide whether the values are satisfactory or not,\u003c/li\u003e\n  \u003cli\u003edefine target values if they are not, and\u003c/li\u003e\n  \u003cli\u003esystematically measure and improve until success or surrender.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eOptimizing without \u003ca href=\"https://esrally.readthedocs.io/en/stable/\"\u003emeasurement\u003c/a\u003e and without defining goals, on the other hand, is a good method of wasting your time, and consequently, achieving sub-par\nperformance. While there are some simple improvements which amount to “don’t do stupid things” and can be applied practically always without any risk,\nmost are trade-offs: you gain something at the expense of something else. If you apply them inappropriately, you may end up with expenses but without the gains.\nMany optimizations’ effectiveness varies a lot depending on the kind of data in the index or specific query patterns generated by your users, so, for example\nyou may introduce an optimization whose effect is negligible, but whose cost (e.g. in increased complexity and thus maintenance cost) is significant.\u003c/p\u003e\n\n\u003ch2 id=\"blindly-trusting-what-you-read-on-the-web\"\u003eBlindly trusting what you read on the web\u003c/h2\u003e\n\n\u003cp\u003eThis leads us to the last tip: if you really want to ruin your ES performance, always trust strangers on the internet and apply their advice\nduly and without hesitation. Obviously, this applies to this very post as well. Another good practice is to never check publication dates, or the ES versions\nthat particular tips apply to.\u003c/p\u003e\n\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eI hope \u003ca href=\"/2021/09/how-to-ruin-elasticsearch-performance-part-i.html\"\u003ePart I\u003c/a\u003e gave you some background on how Elastic works under the hood. In Part II, we discussed various techniques which can affect its performance in\nreal-world scenarios. Armed with this knowledge, you will be able to make or break Elasticsearch performance: the choice is yours.\u003c/p\u003e\n","contentSnippet":"It’s easy to find resources about improving Elasticsearch performance, but what if you wanted to reduce it?\nIn Part I of this two-part series we looked under the hood in order to learn how\nES works internally. Now, in Part II, is the time to apply this knowledge in practice and ruin our ES performance. Most tips should also be applicable to\nSolr, raw Lucene, or, for that matter, to any other full-text search engine as well.\nUsing complex boolean queries\nA consequence of the algorithms outlined in Part I is that simple queries, such as finding\na document containing two or three specific words, are relatively cheap to compute. We can easily increase the cost by making the queries more complex. This\ncomplexity is easily achieved by using boolean queries which allow\narbitrary boolean expressions, including nested subexpressions.\nA “flat” query, even with many words, boils down to a single AND/OR operation (though potentially with many lists). Since a search engine is usually\nsmart enough to sort these lists by length, it can execute such queries really fast. But what happens if we use a complex boolean expression? Let’s compare\ntwo example queries:\nQ1: find books which contain all of the words: “I like apples”\nQ2: find books which contain all of the words: “I like apples” or “I like oranges” and were published in 2020 or 2021 and are at least 100 pages long\nLet us now look at the boolean expressions which correspond to these queries:\nQ1: I AND like AND apples\nQ2: ((I AND like AND apples) OR (I AND like AND oranges)) AND (2020 OR 2021) AND (pages \u003e= 100)\nClearly, there is much more stuff to compute in the case of Q2, and the query will take more time, accordingly. Even though from the end user’s perspective,\nwe only added a few filters, the complexity of the query rose dramatically. For Q1, we need to perform 2 AND operations. For Q2, we end up with\n6 AND operations and 2 OR operations. However, this query is probably still much worse for performance than it may seem.\nLet’s start analyzing this query from the bottom up.\nThe expression 2020 OR 2021 is a little gem that looks innocent, but is actually quite expensive. As you remember, the cost of an OR operation is proportional\nto the sum of the sizes of input lists. The lists of books published in a year are probably quite long, so the cost of merging two will be quite high.\nAs a bonus, we get an even longer list as a result and this long list will take part in any computations that follow. So here are the takeaways:\nOR operations are costly,\neven more so when inputs are large document sets;\nsubqueries (parentheses in the logical expression) cause temporary postings lists to be created, which then take part in further calculations and so their\nsizes affect query performance.\nLooking further at our query, we see that even more temporary document ID lists will have to be created: one for each pair of parentheses. These results have\nto be computed, and since they are temporary partial results, they will have to be stored in memory since they cannot be retrieved from the index directly.\nAlso note that subqueries can hinder many optimizations search engines employ. I mentioned earlier that Lucene sorts postings lists by length when AND-ing\nthem together. This can only work reliably if list lengths are known. For a postings list of a single word, its length is stored in the index and known exactly\nup-front. For a nested subexpression, however, the number of matches is not known before the subexpression is evaluated. But, Lucene needs the number of matches\nin order to prepare the optimal query plan. This leads to a chicken-and-egg problem which Lucene solves by estimating the size of subquery results list based\non the sizes of its constituents. For example, it estimates the result size of a subquery with OR-s as the sum of its input sizes. Being just an estimate, this\nnumber may differ from the actual value, and thus cause suboptimal query performance further up the stack. Takeaway:\nsubqueries are great at hindering global query optimizations.\nAnother reason why subqueries may negatively affect performance becomes apparent with queries such as (a AND b) AND (c AND d). Since AND is an associative\noperation, the expression above gives the same result as a AND b AND c AND d. In the\nversion without parentheses, the optimization of sorting lists by size works globally since all inputs are at the same nesting level, potentially achieving\nbetter performance than the version with nested subexpressions which can only sort the lists within each pair of parentheses separately.\nYou may wonder why anyone would add these parentheses, but such constructs may arise naturally due to the way your code is structured if individual subqueries\nare built by separate methods or classes because they serve different business needs.\nLooking at how long postings lists affect query performance, especially with OR operator, you can see one of the reasons for introducing\nstopwords into search configuration. Words such as the are very common and on one hand they introduce practically\nno meaning at all to the query (with rare exceptions), matching almost all documents anyway, and on the other, they could add immense computational cost.\nObviously, the longest postings list possible is the one containing all documents in the index. And indeed, pure negative queries such as\n“all documents but those with the word x” tend to be very expensive. Surprisingly, AND-ing the full set of documents (the result of a\nmatch_all query) with results of another query is very fast.\nThis is because of a special optimization\nwhich uses the identity ALL AND a = a to simplify those queries so that the expensive computation can be completely avoided.\nThis kind of query rewriting can transform a number of query patterns to queries with the same result but better performance characteristics.\nHowever, this only works for a set of rather simple cases: for example if you do not use match_all query, but create some other query which also happens\nto match all documents, this optimization will not be triggered. Complex query structure with subqueries can effectively disable such optimizations as well.\nThinking about indexing and index segments, you have to notice that merging partial results from each segment is an operation similar to OR-ing (though it\nadditionally has to account for document removal and updates). This leads to the conclusion that having many segments hurts search performance, especially\nfor popular keywords whose postings lists are large to start with. Indeed, this actually happens. Performance may vary significantly depending on the number\nof segments, and the optimum is having just a single segment in your index. In Elastic, you can use the\nforce merge API to reduce the number of segments after indexing.\nI have actually worked with a product in which data was never indexed incrementally, but instead the whole index was rebuilt from scratch and force-merged to a single\nsegment after each update. This was a relatively small index with high search traffic, so big gains in search performance (on the order of two times shorter response\ntimes) were a justifiable reason for this seemingly wasteful indexation process.\nComplex queries in disguise\nSome queries seem simple, but are actually very complex for the search engine to handle. One example is prefix queries such as cat* (which matches documents\ncontaining any words starting with cat). It turns out that unless you do something special, such a query is likely to be handled as an OR-query with all words\nmatching the prefix: (cat OR catamaran OR catapult OR category OR ...). Keeping in mind that queries with the OR operator can be expensive, you see the risk:\nthere may be lots and lots of words in the resulting expression, increasing the cost of merging their corresponding postings lists. In most datasets, a query such as a*,\nwith probably thousands of individual postings lists, each containing millions of documents, can take ages to finish and even bring down the whole cluster.\nAnother type of query that looks simple at first glance but can (or rather, used to) be very costly is range searches in numeric and date fields. Let’s say you want to limit\nyour query to only documents modified between 2020-01-01 and 2020-12-31. How costly could that be? The inverted index maps individual values to lists of\ndocument IDs. If each value in the index corresponds to a single day, and the documents are evenly spread throughout the year, there will be 366 lists to join\nwith the OR operator. If the data is indexed with millisecond resolution, there will be many more, with performance becoming even worse.\nFortunately, these issues have been known for a long time, and there are a number of solutions in place. For text fields, you can enable\nprefix indexing which creates special structures in the index which\ncontain merged postings lists so that they don’t have to be computed at query time. Range queries on numeric and date fields are now optimized by default\nin Elasticsearch by creating additional structures in the index\nas well, though with a particularly nasty data set, you might still be able to trigger some issues. Note that these solutions are space-time tradeoffs\n(speeding up searches at the cost of larger index), and as with any tradeoff, there is always some risk of shooting yourself in the foot. Also, new versions\nintroduce new optimizations, so behavior may well change between ES versions.\nInterestingly, some preconceptions related to performance are very persistent (not only in the full-text search field), and you may run into people\nrecommending optimizations which made sense ten years ago, but may be counterproductive now. For example,\nrange searches have been efficient for ten years, and apart from extreme cases, you should\nnot need to worry about them too much now.\nAs a side note, ES tries to protect you from yourself and by default disables some types of queries that are likely to be costly: you have to\nexplicitly enable them if you know what\nyou’re doing and want to use them.\nReturning lots of search results\nElasticsearch indexes may be huge, often searching millions and billions of documents, but usually only a tiny fraction of these documents match each query’s\ncriteria, and out of those, only a handful (10 or so) are returned to the end user. Increasing the number of documents returned is detrimental to search performance\nin many ways:\nSome algorithms, such as finding the top N results when sorting, have complexity which depends on N:\nthey are faster if N is much smaller than the total number of matches, and become slower as N grows.\nSome operations a full-text search engine performs are proportional to the number of documents returned (linear complexity). As you remember, just finding matches is very fast since it\nuses inverted indices, but in order to actually return the documents’ contents, they have to be fetched from document store, and this operation scales linearly\nwith the number of documents returned. So, if you fetch 100 documents instead of 10, this part takes around ten times longer. Same goes for highlighting\nquery terms. The amount of data transferred over the network scales similarly.\nAggregations such as grouping documents by a field’s value may also have linear complexity (the number of documents returned being the input size).\nAlso note that paging the results (e.g. retrieving 100 pages of 10 documents each instead of a single request asking for 1000 documents) helps only a little.\nThe problem is that in order to find documents on positions 991-1000, Elastic has to find the complete list of results 1-1000 first, and only then take the last\n10 items. This means the cost of fetching documents from storage is indeed proportional to 10, but the cost of performing set operations on postings lists\nand aggregations as well as memory usage is still proportional to 1000.\nSo, if you think you can have millions of documents in ES and can just retrieve them all (or some large subset) using a simple query, you may be in for a surprise.\nThere are specialized APIs for such a use case, but they all have\ntheir limitations.\nAssuming Elastic knows as much about your data as you do\nMuch of the discussion up to this point revolved around replacing boolean expressions with their equivalents that have different performance characteristics.\nSome of these transformations are always correct since both expressions can be proven equal by means of boolean algebra.\nHowever, sometimes two forms of a query are equivalent only within a specific data set. Despite many smart optimizations used by modern full-text search\nengines, by using knowledge about your dataset you can often achieve more in terms of increasing or decreasing search performance than by relying on\nmathematics alone.\nA simple example of using this knowledge in practice is improving performance by removing subqueries which are redundant due to the nature of the data.\nSuppose your index contains both printed and online publications. Only online publications have a URL. By following the simplest logic, if you wanted to find\nan online publication by URL, you would issue a query such as type:online AND url:value. This will work, although you could query just url:value as well.\nHowever, it requires that you know something about your data, namely that only online publications have any value set in the url field.\nObviously, this simplified query will be faster than the original.\nWhere you can’t avoid complex queries, you can still use your domain knowledge to improve or reduce performance. For example, since the cost of merge operations\ndepends on sizes of inputs, knowing that a particular subquery is likely to return many or few results (query selectivity) and modifying the query in a way\nin which the sizes of consecutive intermediate results diminish faster may boost performance, while relying only on Elastic’s optimizations may result in\nsub-par performance.\nSuppose (a real-world example) there is an index with two types of documents whose counts differ wildly: documents of type 1 make up 99% of the index while\ntype 2 amounts to just 1% of all documents. Certain queries must be limited to just a single type. The obvious way to filter these results is to add a clause\nsuch as ... AND type:1 and ... AND type:2, correspondingly, but replacing the first one with ... AND NOT type:2 may be faster since the results list for\ntype 2 is much shorter than for type 1. If the filters can be combined (e.g. by the user checking checkboxes in a GUI), and the user selects both types,\nmeaning effectively no filtering by type, it is probably much more efficient to simply remove the filter from the query than to add a ... AND (type:1 OR type:2)\nclause.\nAs you may have already realized, not only boolean queries’ but also range queries’ performance may depend a lot on your data, for example on a field’s\ncardinality (the number of unique values). One of the more spectacular ways of shooting yourself in the foot is applying a pattern which normally helps\nperformance, but in your particular case, due to a specific distribution of a field’s values, does just the opposite. Such situations may be very difficult\nto discover if you do not precisely track performance before and after each significant change. Sneakily placing such a pattern in your code can be a great way\nto end up with low performance difficult to explain.\nFor a real life example, consider the rule of thumb that if you don’t care about a subquery’s score, using filter subqueries within a bool query\nresults in faster response times than using must subqueries since the former do not need to update matching documents’ scores.\nIn our advertising system, we match ads in a way mostly consistent with the way we match organic results. We match ads by keywords, but we also take\ninto account criteria such as delivery methods selected by the user. In the latter case, the fact that a sponsored offer\nis available with some delivery method only affects which offers match, but does not affect their scores. This is a perfect use case for filter queries.\nHowever, we also use function score query.\nFunction score query allows us to combine a document’s score resulting from how well it matches our keywords with additional factors.\nFunction score query accepts an embedded query — only documents matching this query have their scores modified. Symbolically, we could express it as our\ncomplete query being: function_score_query(keyword_subquery AND filters_subquery). At one point, I wanted to optimize the performance of this query, and\nfollowing the abovementioned rule of thumb, thought that it would make sense to move filters_subquery outside of function_score_query since filters need\nnot participate in score calculations. This resulted in the query filters_subquery AND function_score_query(keyword_subquery) and should have\nimproved search performance. However, upon running performance tests, to my surprise I realized these changes actually made performance worse. The reason was,\nwith the filters moved outside function_score_query, function_score_query had to modify the scores of a larger number of documents and for the particular\ndata I had in my index, the added cost of rescoring more documents was greater than the savings achieved by not having to calculate the score for these\ndocuments in the first place. This just shows that with performance tuning, YMMV, always.\nTreating search and indexing as two separate problems\nYou might be tempted to think of Elasticsearch as yet another database. If you do, you are likely to run into many issues, including performance problems.\nOne of the main things that set ES apart from most databases, whether they be SQL or NoSQL, is the\nsearch-indexing asymmetry.\nIn contrast to a normal database, in Elasticsearch you can’t just insert a bunch of documents: this process triggers indexing, creates new segments, potentially\ntriggers segment merges, has to propagate replicas and handle consistency within the cluster,\netc. This may all affect performance in interesting ways. While indices of some kind are used in pretty much all databases, in ES they play\na central role. Another important difference to databases is that Elastic data model favors, and often forces, very much denormalized data. This is\ncommon with NoSQL databases but in ES, it is even more extreme.\nIn particular, since ES is — in most cases — more about search performance than anything else, it is a common optimization to move cost from search time to\nindexing time when possible, and many such optimizations result in an even more denormalized data model.\nFor example, let’s consider an index of offers such as you may find in an online store. Each offer may be available with a free return option, but\nthere’s a catch: while the client only sees a single checkbox in the UI, internally there are several types of free returns, e.g. free return by package locker\nand free return by post. The natural way to handle this would be to index each of these two flags and then to search for offers having either of those flags.\nIt would also be a step towards our goal of ruining Elasticsearch search performance, especially if the number of values was 200 rather than 2.\nThe reason it works this way is that there are lots and lots of offers matching any of these flags: probably around 90% match one and around 90% match the other\n(with, obviously, a large number matching both). Going back to the section about OR operator, you will notice that having two very long\ninput lists is about the worst case for OR operator efficiency. A usually reasonable trade-off in such a case is to move the cost to indexing-time, and\nto index with the document just a single flag, “free return”, which will improve search performance (at the cost of reducing indexing performance by just a tiny amount).\nNote that this was a very simple case and sometimes indexing denormalized data may increase index size significantly, in which case the trade-off may become\nless obvious.\nAnother quirk is the mutual interaction between indexing and search performance. Interaction between reads and writes happens in practically any database,\nbut with Elastic, it is easier for it to become an issue due to the relatively high CPU and I/O cost of indexing. Ignoring this fact and treating\nsearch and indexing performance as two independent issues is a recipe for poor performance in both areas.\nJumping right into optimization without checking first\nOne effective method of achieving inferior performance, which works not only with Elasticsearch, is jumping\nright into optimization without first analyzing the problem, and, even better, not checking if there is a problem at all. It is a boring thing to repeat\nover and over, but the only way to improve performance is to:\nfirst, measure the baseline you are starting from (avoiding common pitfalls along the way),\ndecide whether the values are satisfactory or not,\ndefine target values if they are not, and\nsystematically measure and improve until success or surrender.\nOptimizing without measurement and without defining goals, on the other hand, is a good method of wasting your time, and consequently, achieving sub-par\nperformance. While there are some simple improvements which amount to “don’t do stupid things” and can be applied practically always without any risk,\nmost are trade-offs: you gain something at the expense of something else. If you apply them inappropriately, you may end up with expenses but without the gains.\nMany optimizations’ effectiveness varies a lot depending on the kind of data in the index or specific query patterns generated by your users, so, for example\nyou may introduce an optimization whose effect is negligible, but whose cost (e.g. in increased complexity and thus maintenance cost) is significant.\nBlindly trusting what you read on the web\nThis leads us to the last tip: if you really want to ruin your ES performance, always trust strangers on the internet and apply their advice\nduly and without hesitation. Obviously, this applies to this very post as well. Another good practice is to never check publication dates, or the ES versions\nthat particular tips apply to.\nSummary\nI hope Part I gave you some background on how Elastic works under the hood. In Part II, we discussed various techniques which can affect its performance in\nreal-world scenarios. Armed with this knowledge, you will be able to make or break Elasticsearch performance: the choice is yours.","guid":"https://blog.allegro.tech/2021/10/how-to-ruin-elasticsearch-performance-part-ii.html","categories":["tech","full-text search","elasticsearch","elastic","es","performance"],"isoDate":"2021-10-06T22:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"How to ruin your Elasticsearch performance — Part I: Know your enemy","link":"https://blog.allegro.tech/2021/09/how-to-ruin-elasticsearch-performance-part-i.html","pubDate":"Thu, 30 Sep 2021 00:00:00 +0200","authors":{"author":[{"name":["Michał Kosmulski"],"photo":["https://blog.allegro.tech/img/authors/michal.kosmulski.jpg"],"url":["https://blog.allegro.tech/authors/michal.kosmulski"]}]},"content":"\u003cp\u003eIt’s easy to find resources about \u003cem\u003eimproving\u003c/em\u003e \u003ca href=\"https://www.elastic.co/elastic-stack\"\u003eElasticsearch\u003c/a\u003e performance, but what if you wanted to \u003cem\u003ereduce\u003c/em\u003e it?\nThis is Part I of a two-post series, and will present some ES internals. In \u003ca href=\"/2021/10/how-to-ruin-elasticsearch-performance-part-ii.html\"\u003ePart II\u003c/a\u003e\nwe’ll deduce from them a collection of select tips which can help you ruin your ES performance in no time. Most should also be applicable to\n\u003ca href=\"https://solr.apache.org/\"\u003eSolr\u003c/a\u003e, raw \u003ca href=\"https://lucene.apache.org/\"\u003eLucene\u003c/a\u003e, or, for that matter, to any other full-text search engine as well.\u003c/p\u003e\n\n\u003cp\u003eSurprisingly, a number of people seem to have discovered these tactics already, and you may even find some of them used in your own production code.\u003c/p\u003e\n\n\u003ch2 id=\"know-your-enemy-know-your-battlefield\"\u003eKnow your enemy, know your battlefield\u003c/h2\u003e\n\n\u003cp\u003eIn order to deal a truly devastating blow to Elastic’s performance, we first need to understand what goes on under the hood. Since full-text search is\na complex topic, consider this introduction both simplified and incomplete.\u003c/p\u003e\n\n\u003ch2 id=\"index-and-document-contents\"\u003eIndex and document contents\u003c/h2\u003e\n\n\u003cp\u003eIn most full-text search engines data is split into two separate areas: the index, which makes it possible to find documents (represented by some sort of document ID)\nmatching specified criteria, and \u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/6.8/mapping-store.html\"\u003edocument storage\u003c/a\u003e which makes it possible\nto retrieve the contents (values of all fields) of a document with specified ID.\nThis distinction improves performance, since usually document IDs will appear multiple times in the index, and it would not make much sense to duplicate all\ndocument contents. IDs can also fit into fixed-width fields which makes managing certain data structures easier. This separation also enables further\nspace savings: it is possible to specify that certain fields will never be searched, and therefore do not need to be in the index, while others might never\nneed to be returned in search results and thus can be omitted from document storage.\u003c/p\u003e\n\n\u003cp\u003eFor certain operations it may be necessary to \u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/6.8/doc-values.html\"\u003estore field values within the index itself\u003c/a\u003e,\nwhich is yet another approach.\u003c/p\u003e\n\n\u003ch2 id=\"inverted-index\"\u003eInverted index\u003c/h2\u003e\n\n\u003cp\u003eThe basic data structure full-text search uses is the \u003ca href=\"https://en.wikipedia.org/wiki/Inverted_index\"\u003einverted index\u003c/a\u003e. Basically, it is a map from keywords\nto sorted lists of document IDs, so-called postings lists. The specific data structures used to implement this mapping are many, but are not relevant here.\nWhat matters is that for a single-word query this index can find matching documents very fast: it actually contains a ready-to-use answer. The same\nstructure can, of course, be used not only for words: in a numeric index, for example, we may have a ready-to-use list with IDs of documents containing\nthe value 123 in a specific field.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2021-09-30-how-to-ruin-elasticsearch-performance/postings-lists.webp\" alt=\"Postings lists — lists of document IDs containing each individual word\" /\u003e\u003c/p\u003e\n\n\u003ch2 id=\"indexing\"\u003eIndexing\u003c/h2\u003e\n\n\u003cp\u003eThe mechanism for finding all documents containing a single word, described above, is very neat, but it can be so fast and simple only because\nthere is a ready answer for our query in the index. However, in order for it to end up in there, ES needs to perform a rather complex operation called \u003cem\u003eindexing\u003c/em\u003e.\nWe won’t get into the details here, but suffice to say this process is both complex when it comes to the logic it implements, and resource-intensive, since\nit requires information about all documents to be gathered in a single place.\u003c/p\u003e\n\n\u003cp\u003eThis has far-reaching consequences. Adding a new document, which may contain hundreds or thousands of words, to the index, would mean that hundreds or thousands\nof postings lists would have to be updated. This would be prohibitively expensive in terms of performance. Therefore, full-text search engines usually employ\na different strategy: once built, an index is effectively immutable. When documents are added, removed, or modified, a new tiny index containing just the changes\nis created. At query time, results from the main and the incremental indices are merged. Any number of these incremental indices, called \u003ca href=\"https://lucene.apache.org/core/8_9_0/core/org/apache/lucene/codecs/lucene87/package-summary.html#Segments\"\u003esegments\u003c/a\u003e in\nElastic jargon, can be created, but the cost of merging results at search time grows quickly with their number. Therefore, a special process of segment merging\nmust be present in order to ensure that the number of segments (and thus also search latency) does not get out of control. This, obviously, further increases\ncomplexity of the whole system.\u003c/p\u003e\n\n\u003ch2 id=\"operations-on-postings-lists\"\u003eOperations on postings lists\u003c/h2\u003e\n\n\u003cp\u003eSo far we talked about the relatively simple case of searching for documents matching a single search term. But what if we wanted to find documents\ncontaining multiple search terms? This is where Elastic needs to combine several postings lists into a single one. Interestingly, the same issue arises\neven for a single search term if your index has multiple segments.\u003c/p\u003e\n\n\u003cp\u003eA postings list represents a set of document IDs, and most ways of matching documents to search terms correspond to boolean operations on those sets.\nFor example, finding documents which contain both \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eterm1\u003c/code\u003e and \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eterm2\u003c/code\u003e corresponds to the logical operation \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eset1 AND set2\u003c/code\u003e (intersection of sets) where\n\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eset1\u003c/code\u003e and \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eset2\u003c/code\u003e are the sets of documents matching individual search terms. Likewise, finding documents containing any word out of several corresponds\nto the logical \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eOR\u003c/code\u003e operation (sum of sets) and documents which contain one term, but do not contain another, correspond to \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eAND NOT\u003c/code\u003e operator (difference\nof sets).\u003c/p\u003e\n\n\u003cp\u003eThere are many ways these operations can be implemented in practice, with search engines using lots of optimizations. However, some constraints on the\ncomplexity remain. Let’s take a look at one possible implementation and see what conclusions can be drawn.\u003c/p\u003e\n\n\u003cp\u003eWhile the operations described below can be generalized to work on multiple lists at once, for simplicity we’ll just discuss operations which are binary,\ni.e. which take two arguments. Conclusions remain the same for higher arity.\u003c/p\u003e\n\n\u003cp\u003eIn the algorithms below, we’ll assume each postings list is an actual list of integers (doc IDs), sorted in ascending order, and that their sizes\nare \u003cem\u003en\u003c/em\u003e and \u003cem\u003em\u003c/em\u003e.\u003c/p\u003e\n\n\u003ch3 id=\"or-operator\"\u003eOR\u003c/h3\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2021-09-30-how-to-ruin-elasticsearch-performance/list-merging-or.webp\" alt=\"Example algorithm for computing results of OR operation\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eThe way to merge two sorted lists in an OR operation is straightforward (and it is also the reason for the lists to be sorted in the first place).\nFor each list we need to keep a pointer which will indicate the current position. Both pointers start at the beginning of their corresponding lists.\nIn each step we compare the values (integer IDs) indicated by the pointers, and add the smaller one to the result list. Then, we move that pointer forward. If the values\nare equal, we add the value to the result just once and move both pointers. When one pointer reaches the end of its list, we copy the remainder of the second\nlist to the end of result list, and we’re done. Like each of the input lists, the result is a sorted list without duplicates.\u003c/p\u003e\n\n\u003cp\u003eIf you are familiar with \u003ca href=\"https://en.wikipedia.org/wiki/Merge_sort\"\u003emerge sort\u003c/a\u003e, you will notice that this algorithm corresponds to its merge phase.\u003c/p\u003e\n\n\u003cp\u003eSince the result is a sum of the two sets, its size is at least \u003cem\u003emax(m, n)\u003c/em\u003e (in the case one set is a subset of the other) and at most\n\u003cem\u003em + n\u003c/em\u003e (in the case the two sets are disjoint). Due to the fact that the cursor has to go through all entries in each of the lists, the\nalgorithm’s complexity is O(n+m). Even for any other algorithm, since the size of the result list may reach \u003cem\u003em + n\u003c/em\u003e, and we have to generate that list,\ncomplexity of O(n+m) is expected.\u003c/p\u003e\n\n\u003cp\u003eThe result does not depend on the order of lists (OR operation is symmetric), and performance is not (much) affected by it, either.\u003c/p\u003e\n\n\u003ch3 id=\"and-and-and-not\"\u003eAND and AND NOT\u003c/h3\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2021-09-30-how-to-ruin-elasticsearch-performance/list-merging-and.webp\" alt=\"Example algorithm for computing results of AND / AND NOT operations\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eCalculating the intersection of two sets (what corresponds to the logical AND operator) or their difference (AND NOT) are very similar operations.\nJust as when calculating the sum of sets, we need to maintain two pointers, one for each list. In each step of the iteration we look at the current value\nin the first list and then try to find that value in the second list, starting from the second list’s pointer’s position. If we find the value, we add it\nto the result list, and move the second list’s pointer to the corresponding position. If the value can’t be found, we advance the pointer to the first\nitem after which the searched-for value would be. Once the second list’s pointer reaches the end, we are done.\u003c/p\u003e\n\n\u003cp\u003eThe algorithmic complexity of these two operations differs quite a bit from that of OR operation. First of all, a new sub-operation of searching for a value\nin the second list is used. It can be implemented in a number of ways depending on the data structures (flat array, skip list, various trees, etc.). For a simple\nsorted list stored in an array, we could use binary search whose complexity is O(log(\u003cem\u003em\u003c/em\u003e)). Things get a little more complicated since we only search starting\nfrom current position rather than from the beginning, but let’s skim over this for now. What matters is that we perform a search in the second list\nfor each item from the first one: the complexity is no longer symmetric between the two lists. If we change the order of the lists, the result of AND operation\ndoes not change, but the cost of performing the calculation does.\nIt pays to have the shorter of the two list as the first in order, and the difference can be huge. The cost also depends very much on the data, i.e. how\nbig the intersection of the two lists is. If the intersection is empty, even looking for the first list’s first element in the second list will move the second\nlist’s pointer to the end, and the algorithm will finish very quickly. The upper limit on the size of the result list (which in turn puts a lower limit on\nalgorithmic complexity) is \u003cem\u003emin(m, n)\u003c/em\u003e.\u003c/p\u003e\n\n\u003cp\u003eIf we’re performing the AND NOT rather than AND operation, the match condition has to be reversed from \u003cem\u003efound\u003c/em\u003e to \u003cem\u003enot found\u003c/em\u003e. While the result changes when\nwe exchange the two lists, algorithmic properties are the same as for AND, especially the asymmetry in how the first and second list’s size affects the\ncomputational cost.\u003c/p\u003e\n\n\u003cp\u003eIn order to improve performance, many search engines will automatically change the order in which operations are evaluated if it does not alter the end result.\nThis is an example of \u003cem\u003equery rewriting\u003c/em\u003e. In particular, Lucene (and thus also Elasticsearch and Solr)\n\u003ca href=\"https://github.com/apache/lucene/blob/5e0e7a5479bca798ccfe385629a0ca2ba5870bc0/lucene/core/src/java/org/apache/lucene/search/ConjunctionDISI.java#L153\"\u003ereorder lists passed to AND operator\u003c/a\u003e\nso that they are sorted by length in ascending order.\u003c/p\u003e\n\n\u003ch2 id=\"beyond-the-basics\"\u003eBeyond the basics\u003c/h2\u003e\n\n\u003cp\u003eThere are lots of factors which affect Elasticsearch performance and can be exploited in order to make that performance worse, and which I haven’t mentioned\nhere. These include scoring, phrase search, run-time scripting, sharding and replication, hardware, and disk vs memory access just to name a few.\nThere are also lots of minor quirks which are too numerous to list here. Given that you can\n\u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/plugins/6.8/plugin-authors.html\"\u003eextend ES with custom plugins\u003c/a\u003e that can execute arbitrary code, the\nopportunities for breaking things are endless.\u003c/p\u003e\n\n\u003cp\u003eOn the other hand, search engines employ \u003ca href=\"https://www.elastic.co/blog/elasticsearch-query-execution-order\"\u003ea number of optimizations\u003c/a\u003e which may counter\nsome of our efforts at achieving low performance.\u003c/p\u003e\n\n\u003cp\u003eThen again, some of these optimizations may themselves lead to surprising results. For example, often there are two different ways of performing a task,\nand a heuristic is used to choose one or the other. Such heuristics are often simple threshold values: for example, if the number of sub-clauses in a\nquery is above 16, \u003ca href=\"https://github.com/apache/lucene/blob/d5d6dc079395c47cd6d12dcce3bcfdd2c7d9dc63/lucene/core/src/java/org/apache/lucene/search/BooleanWeight.java#L358\"\u003eit will not be cached\u003c/a\u003e.\nLikewise, certain pieces of data may be represented as lists and then suddenly switch to a bitset representation.\nSuch behaviors may be confusing since they make performance analysis more difficult.\u003c/p\u003e\n\n\u003cp\u003eAnyway, even the basic knowledge presented above should allow you to deal some heavy damage to your search performance, so let’s get started.\u003c/p\u003e\n\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eI hope the first part of this post gave you some background on how Elastic works under the hood. In \u003ca href=\"/2021/10/how-to-ruin-elasticsearch-performance-part-ii.html\"\u003ePart II\u003c/a\u003e,\nwe’ll look at how to apply this knowledge in practice to making Elasticsearch performance as bad as possible.\u003c/p\u003e\n","contentSnippet":"It’s easy to find resources about improving Elasticsearch performance, but what if you wanted to reduce it?\nThis is Part I of a two-post series, and will present some ES internals. In Part II\nwe’ll deduce from them a collection of select tips which can help you ruin your ES performance in no time. Most should also be applicable to\nSolr, raw Lucene, or, for that matter, to any other full-text search engine as well.\nSurprisingly, a number of people seem to have discovered these tactics already, and you may even find some of them used in your own production code.\nKnow your enemy, know your battlefield\nIn order to deal a truly devastating blow to Elastic’s performance, we first need to understand what goes on under the hood. Since full-text search is\na complex topic, consider this introduction both simplified and incomplete.\nIndex and document contents\nIn most full-text search engines data is split into two separate areas: the index, which makes it possible to find documents (represented by some sort of document ID)\nmatching specified criteria, and document storage which makes it possible\nto retrieve the contents (values of all fields) of a document with specified ID.\nThis distinction improves performance, since usually document IDs will appear multiple times in the index, and it would not make much sense to duplicate all\ndocument contents. IDs can also fit into fixed-width fields which makes managing certain data structures easier. This separation also enables further\nspace savings: it is possible to specify that certain fields will never be searched, and therefore do not need to be in the index, while others might never\nneed to be returned in search results and thus can be omitted from document storage.\nFor certain operations it may be necessary to store field values within the index itself,\nwhich is yet another approach.\nInverted index\nThe basic data structure full-text search uses is the inverted index. Basically, it is a map from keywords\nto sorted lists of document IDs, so-called postings lists. The specific data structures used to implement this mapping are many, but are not relevant here.\nWhat matters is that for a single-word query this index can find matching documents very fast: it actually contains a ready-to-use answer. The same\nstructure can, of course, be used not only for words: in a numeric index, for example, we may have a ready-to-use list with IDs of documents containing\nthe value 123 in a specific field.\n\nIndexing\nThe mechanism for finding all documents containing a single word, described above, is very neat, but it can be so fast and simple only because\nthere is a ready answer for our query in the index. However, in order for it to end up in there, ES needs to perform a rather complex operation called indexing.\nWe won’t get into the details here, but suffice to say this process is both complex when it comes to the logic it implements, and resource-intensive, since\nit requires information about all documents to be gathered in a single place.\nThis has far-reaching consequences. Adding a new document, which may contain hundreds or thousands of words, to the index, would mean that hundreds or thousands\nof postings lists would have to be updated. This would be prohibitively expensive in terms of performance. Therefore, full-text search engines usually employ\na different strategy: once built, an index is effectively immutable. When documents are added, removed, or modified, a new tiny index containing just the changes\nis created. At query time, results from the main and the incremental indices are merged. Any number of these incremental indices, called segments in\nElastic jargon, can be created, but the cost of merging results at search time grows quickly with their number. Therefore, a special process of segment merging\nmust be present in order to ensure that the number of segments (and thus also search latency) does not get out of control. This, obviously, further increases\ncomplexity of the whole system.\nOperations on postings lists\nSo far we talked about the relatively simple case of searching for documents matching a single search term. But what if we wanted to find documents\ncontaining multiple search terms? This is where Elastic needs to combine several postings lists into a single one. Interestingly, the same issue arises\neven for a single search term if your index has multiple segments.\nA postings list represents a set of document IDs, and most ways of matching documents to search terms correspond to boolean operations on those sets.\nFor example, finding documents which contain both term1 and term2 corresponds to the logical operation set1 AND set2 (intersection of sets) where\nset1 and set2 are the sets of documents matching individual search terms. Likewise, finding documents containing any word out of several corresponds\nto the logical OR operation (sum of sets) and documents which contain one term, but do not contain another, correspond to AND NOT operator (difference\nof sets).\nThere are many ways these operations can be implemented in practice, with search engines using lots of optimizations. However, some constraints on the\ncomplexity remain. Let’s take a look at one possible implementation and see what conclusions can be drawn.\nWhile the operations described below can be generalized to work on multiple lists at once, for simplicity we’ll just discuss operations which are binary,\ni.e. which take two arguments. Conclusions remain the same for higher arity.\nIn the algorithms below, we’ll assume each postings list is an actual list of integers (doc IDs), sorted in ascending order, and that their sizes\nare n and m.\nOR\n\nThe way to merge two sorted lists in an OR operation is straightforward (and it is also the reason for the lists to be sorted in the first place).\nFor each list we need to keep a pointer which will indicate the current position. Both pointers start at the beginning of their corresponding lists.\nIn each step we compare the values (integer IDs) indicated by the pointers, and add the smaller one to the result list. Then, we move that pointer forward. If the values\nare equal, we add the value to the result just once and move both pointers. When one pointer reaches the end of its list, we copy the remainder of the second\nlist to the end of result list, and we’re done. Like each of the input lists, the result is a sorted list without duplicates.\nIf you are familiar with merge sort, you will notice that this algorithm corresponds to its merge phase.\nSince the result is a sum of the two sets, its size is at least max(m, n) (in the case one set is a subset of the other) and at most\nm + n (in the case the two sets are disjoint). Due to the fact that the cursor has to go through all entries in each of the lists, the\nalgorithm’s complexity is O(n+m). Even for any other algorithm, since the size of the result list may reach m + n, and we have to generate that list,\ncomplexity of O(n+m) is expected.\nThe result does not depend on the order of lists (OR operation is symmetric), and performance is not (much) affected by it, either.\nAND and AND NOT\n\nCalculating the intersection of two sets (what corresponds to the logical AND operator) or their difference (AND NOT) are very similar operations.\nJust as when calculating the sum of sets, we need to maintain two pointers, one for each list. In each step of the iteration we look at the current value\nin the first list and then try to find that value in the second list, starting from the second list’s pointer’s position. If we find the value, we add it\nto the result list, and move the second list’s pointer to the corresponding position. If the value can’t be found, we advance the pointer to the first\nitem after which the searched-for value would be. Once the second list’s pointer reaches the end, we are done.\nThe algorithmic complexity of these two operations differs quite a bit from that of OR operation. First of all, a new sub-operation of searching for a value\nin the second list is used. It can be implemented in a number of ways depending on the data structures (flat array, skip list, various trees, etc.). For a simple\nsorted list stored in an array, we could use binary search whose complexity is O(log(m)). Things get a little more complicated since we only search starting\nfrom current position rather than from the beginning, but let’s skim over this for now. What matters is that we perform a search in the second list\nfor each item from the first one: the complexity is no longer symmetric between the two lists. If we change the order of the lists, the result of AND operation\ndoes not change, but the cost of performing the calculation does.\nIt pays to have the shorter of the two list as the first in order, and the difference can be huge. The cost also depends very much on the data, i.e. how\nbig the intersection of the two lists is. If the intersection is empty, even looking for the first list’s first element in the second list will move the second\nlist’s pointer to the end, and the algorithm will finish very quickly. The upper limit on the size of the result list (which in turn puts a lower limit on\nalgorithmic complexity) is min(m, n).\nIf we’re performing the AND NOT rather than AND operation, the match condition has to be reversed from found to not found. While the result changes when\nwe exchange the two lists, algorithmic properties are the same as for AND, especially the asymmetry in how the first and second list’s size affects the\ncomputational cost.\nIn order to improve performance, many search engines will automatically change the order in which operations are evaluated if it does not alter the end result.\nThis is an example of query rewriting. In particular, Lucene (and thus also Elasticsearch and Solr)\nreorder lists passed to AND operator\nso that they are sorted by length in ascending order.\nBeyond the basics\nThere are lots of factors which affect Elasticsearch performance and can be exploited in order to make that performance worse, and which I haven’t mentioned\nhere. These include scoring, phrase search, run-time scripting, sharding and replication, hardware, and disk vs memory access just to name a few.\nThere are also lots of minor quirks which are too numerous to list here. Given that you can\nextend ES with custom plugins that can execute arbitrary code, the\nopportunities for breaking things are endless.\nOn the other hand, search engines employ a number of optimizations which may counter\nsome of our efforts at achieving low performance.\nThen again, some of these optimizations may themselves lead to surprising results. For example, often there are two different ways of performing a task,\nand a heuristic is used to choose one or the other. Such heuristics are often simple threshold values: for example, if the number of sub-clauses in a\nquery is above 16, it will not be cached.\nLikewise, certain pieces of data may be represented as lists and then suddenly switch to a bitset representation.\nSuch behaviors may be confusing since they make performance analysis more difficult.\nAnyway, even the basic knowledge presented above should allow you to deal some heavy damage to your search performance, so let’s get started.\nSummary\nI hope the first part of this post gave you some background on how Elastic works under the hood. In Part II,\nwe’ll look at how to apply this knowledge in practice to making Elasticsearch performance as bad as possible.","guid":"https://blog.allegro.tech/2021/09/how-to-ruin-elasticsearch-performance-part-i.html","categories":["tech","full-text search","elasticsearch","elastic","es","performance"],"isoDate":"2021-09-29T22:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"Evolution of web performance culture","link":"https://blog.allegro.tech/2021/09/evolution-of-web-performance-culture.html","pubDate":"Thu, 23 Sep 2021 00:00:00 +0200","authors":{"author":[{"name":["Jerzy Jelinek"],"photo":["https://blog.allegro.tech/img/authors/jerzy.jelinek.jpg"],"url":["https://blog.allegro.tech/authors/jerzy.jelinek"]}]},"content":"\u003cp\u003eThe main goal of boosting website performance is to improve the user experience. In theory,\na satisfied customer is more likely to use a particular company’s services, which is then reflected in business results.\nHowever, from my own experience I can say that not every change can be easily converted into money.\nI would like to tell you how to reconcile these two worlds, how to convince the business that the benefits of\nbetter performance are a long-term investment, and how to streamline the development process during the design or code writing process.\u003c/p\u003e\n\n\u003cp\u003eWeb performance is a challenging and complex subject. It involves working at the intersection of content management,\nfrontend, backend and the network layer. Rarely does a single change make a dramatic difference in performance,\nonly the cumulative effort of small improvements in each of these areas produces noticeable results.\u003c/p\u003e\n\n\u003cp\u003eAs the team responsible for the performance of Allegro, we are responsible for implementing various optimizations,\nbut most of all we show other teams which modifications in their projects will positively affect the performance\nof the whole site. Our duty is to create the friendliest, performance-supporting work environment for developers\nand help non-technical people to understand the idea behind it.\u003c/p\u003e\n\n\u003cp\u003eWe would like to illustrate by our example how this can be achieved.\u003c/p\u003e\n\n\u003ch2 id=\"stage-one--measuring-the-web-performance\"\u003eStage One — Measuring The Web Performance\u003c/h2\u003e\n\n\u003cp\u003eAt Allegro, we want to know if and how a given functionality affects the user as well as our business metrics.\nIn order to prove our hypothesis about performance impact we had to prepare a whole mechanism that allows us\nto track and analyze performance changes. I described it in greater detail in my first article titled\n\u003ca href=\"/2021/06/measuring-web-performance.html\"\u003eMeasuring The Web Performance\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eOnly then we could start optimizing our pages. Our actions brought the expected effect — we made progress,\nbut the pace was not sufficient. We lacked the support of business people, who would see profit in all of this.\u003c/p\u003e\n\n\u003ch2 id=\"stage-two--make-it-clear-that-performance-is-important\"\u003eStage Two — Make it clear that performance is important\u003c/h2\u003e\n\n\u003cp\u003eWe have gone to great lengths to make the entire organization realize that the gains from web performance are long-term and important overall.\u003c/p\u003e\n\n\u003cp\u003eEveryone subconsciously knows that a faster site improves user experience. The earlier users are able to see a page and use it,\nthe more often they are likely to do so and return. However, we had a problem proving that it truly makes our company earn more,\nin the end this is what every business is about.\u003c/p\u003e\n\n\u003cp\u003eThe first milestone turned out to be a test conducted together with the SEO team. It was an A/B test,\nwhere some users got an optimized offers list page that was loading faster, and the rest got the original page.\nIt turned out that all examined pages were added to Google cache (previously there were only a few of them),\nthe number of clicks, average ranking position and number of views increased from a few to several percent\nand the expected business profit from such a change was at 13% of the current GMV originating from organic traffic.\nAlthough being only a proof of concept, this experiment turned out to be an enabler for our next steps.\nIt helped us understand better what we were aiming for.\u003c/p\u003e\n\n\u003cp\u003eThis experiment has opened the way for us to make more optimizations, it also provided us with a solid argument\nthat convinced other product teams. However, we still felt unsatisfied — if performance affects\nGMV indirectly through SEO then are we able to prove a direct correlation as well? We had plenty of data,\nbut we lacked the analytical expertise to process it, therefore, we asked our business analysts to help us.\nBased on historical performance* and business data, they were able to confirm the impact on business metrics!\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eEach 100ms slowdown of First Input Delay results in an average drop in GMV of 3%.\u003cbr /\u003e\nEach 100ms slowdown of First Contentful Paint results in an average drop in GMV of 1.5%.\u003cbr /\u003e\nEach 100ms slowdown of Largest Contentful Paint results in an average drop in GMV of 0.5%.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e*The data comes from our real user measurements, not from synthetic tests.\u003c/p\u003e\n\n\u003ch2 id=\"stage-three--support-for-both-business-and-developers\"\u003eStage Three — Support for both business and developers\u003c/h2\u003e\n\n\u003cp\u003eAfter confirming our hypothesis, we had to implement a number of measures to ensure that web performance\nis taken into consideration throughout the entire process of delivery for all functionalities.\u003c/p\u003e\n\n\u003ch3 id=\"teaching\"\u003eTeaching\u003c/h3\u003e\n\n\u003cp\u003eOne of the main tasks of my team is to prepare the awareness campaign of our colleagues.\nTherefore, we periodically conduct two types of training:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eFor engineers, where we focus on the technical part including how to use the available tools to write optimal code.\u003c/li\u003e\n  \u003cli\u003eFor other employees (especially Product Managers), where we explain why performance is important and what benefits it brings.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eWe assume that knowledge should be shared, that is why we describe each interesting case, experiment or bug fix on our internal blog.\nThanks to that we mitigate the risk that bad patterns will be repeated in the future.\u003c/p\u003e\n\n\u003cp\u003eHowever, the best way to learn is to work with us directly, so we encourage everyone to visit us as part of the\n\u003ca href=\"/2019/09/team-tourism-at-allegro.html\"\u003eteam tourism\u003c/a\u003e initiative.\u003c/p\u003e\n\n\u003ch3 id=\"supporting-technical-teams\"\u003eSupporting technical teams\u003c/h3\u003e\n\n\u003cp\u003eIn our team we believe that we should automate every task possible. We want our tools to support\nthe work of our engineers, so that they don’t have to remember to run performance tests,\ncheck the size of the resulting files, etc. That is why we have prepared several checks that apply to components development\nin our \u003ca href=\"/2016/03/Managing-Frontend-in-the-microservices-architecture.html\"\u003eMicro Frontends architecture\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch4 id=\"automatic-page-scanner\"\u003eAutomatic page scanner\u003c/h4\u003e\n\n\u003cp\u003eThat’s where the whole automation story started. To detect problems with assets we had to check each page manually.\nThis was neither convenient nor scalable, so we created our first bot, which used PageSpeed Insights to check if:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eassets are cached long enough,\u003c/li\u003e\n  \u003cli\u003etheir sizes on the page are appropriate,\u003c/li\u003e\n  \u003cli\u003ethere are any assets which are not minified,\u003c/li\u003e\n  \u003cli\u003eimages are in the right format and size,\u003c/li\u003e\n  \u003cli\u003esome images should be loaded lazily.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAfter detecting problems, we checked the owners of the asset or part of the page and notified them on Slack.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2021-09-23-evolution-of-web-performance-culture/brylant-bot.png\" alt=\"Brylant Bot\" title=\"Brylant Bot\" /\u003e\u003c/p\u003e\n\n\u003ch4 id=\"automatic-comments-in-pull-requests\"\u003eAutomatic comments in pull requests\u003c/h4\u003e\n\n\u003cp\u003eTwo comments are generated while building the component. The first one presents a comparison of assets size\nwith the target branch and the estimated cost of the change.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2021-09-23-evolution-of-web-performance-culture/gh-sizes.png\" alt=\"Asset size comparison\" title=\"Asset size comparison\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eIf the size exceeds the declared threshold, our entire team is automatically added as reviewers to the pull request.\u003c/p\u003e\n\n\u003cp\u003eAdditionally, to detect the culprit faster, a\n\u003ca href=\"https://github.com/webpack-contrib/webpack-bundle-analyzer\"\u003eWebpack Bundle Analyzer\u003c/a\u003e report is generated.\u003c/p\u003e\n\n\u003cp\u003eIn the second one, Lighthouse reports for target and feature branches are compared in order to catch performance metrics’ regressions at this early stage.\nEach component has a list of predefined presets (input data) and a server that displays them.\nThis functionality is used for: development, visual regression, snapshot and performance testing.\nLighthouse report is generated for one or more predefined states every time the component is built.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2021-09-23-evolution-of-web-performance-culture/lighthouse-report.png\" alt=\"Lighthouse report\" title=\"Lighthouse report\" /\u003e\u003c/p\u003e\n\n\u003ch4 id=\"automatic-notifications\"\u003eAutomatic notifications\u003c/h4\u003e\n\n\u003cp\u003eMy team is notified on Slack every time a new dependency is added to any of the components.\nWe want to make sure that the libraries used are optimal and have no better (smaller, faster) replacements.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2021-09-23-evolution-of-web-performance-culture/bot-deps.png\" alt=\"Dependencies notification\" title=\"Dependencies notification\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eWe get similar notifications when assets size changes by at least 5% compared to the target branch.\nWe want to make sure that, for example, treeshaking hasn’t broken down or some other change affecting the size has not occurred.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2021-09-23-evolution-of-web-performance-culture/bot-sizes.png\" alt=\"Size notification\" title=\"Size notification\" /\u003e\u003c/p\u003e\n\n\u003ch4 id=\"eslint\"\u003eESlint\u003c/h4\u003e\n\n\u003cp\u003eWe use it not only for formatting but also for finding violations in our code using custom rules.\nWe have created several rules to support engineers in their daily work. You can read about a sample implementation\nin the post “\u003ca href=\"/2020/08/using-eslint.html\"\u003eUsing ESLint to improve your app’s performance\u003c/a\u003e” on our blog.\u003c/p\u003e\n\n\u003ch4 id=\"analyses\"\u003eAnalyses\u003c/h4\u003e\n\n\u003cp\u003eWe get requests from other teams to analyze their components or sites. Sometimes they lack the time budget\nfor such analysis, but would like to know what to improve.\u003c/p\u003e\n\n\u003ch3 id=\"research-and-development\"\u003eResearch and development\u003c/h3\u003e\n\n\u003cp\u003eKeep in mind that working on web performance is a continuous work. Every now and then new solutions,\nwhich may have a positive impact on the loading speed, appear on the market. Therefore, together with our team,\nwe run a series of tests to see if it makes sense to adopt a given solution.\u003c/p\u003e\n\n\u003ch3 id=\"appreciation-culture\"\u003eAppreciation culture\u003c/h3\u003e\n\n\u003cp\u003eWe believe that the carrot is better than the stick, so we praise other teams for the achievements\nrelated to improving performance. Some time ago we used to write it down in the form of a newsletter,\nnow we talk about it during our sprint summaries.\u003c/p\u003e\n\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eWe are constantly working on data collection, monitoring, awareness raising, optimization and research,\nwhich leads to a situation where more and more managers come to us for consultation.\nThey know that performance is important and needs to be taken care of. Allegro is constantly evolving,\nnew content and features are being created, without working on performance the site will slow down.\nHowever, we already have a whole arsenal of capabilities to help us deal with this.\nWe are no longer fighting alone as the Webperf team, but as an entire organization.\u003c/p\u003e\n","contentSnippet":"The main goal of boosting website performance is to improve the user experience. In theory,\na satisfied customer is more likely to use a particular company’s services, which is then reflected in business results.\nHowever, from my own experience I can say that not every change can be easily converted into money.\nI would like to tell you how to reconcile these two worlds, how to convince the business that the benefits of\nbetter performance are a long-term investment, and how to streamline the development process during the design or code writing process.\nWeb performance is a challenging and complex subject. It involves working at the intersection of content management,\nfrontend, backend and the network layer. Rarely does a single change make a dramatic difference in performance,\nonly the cumulative effort of small improvements in each of these areas produces noticeable results.\nAs the team responsible for the performance of Allegro, we are responsible for implementing various optimizations,\nbut most of all we show other teams which modifications in their projects will positively affect the performance\nof the whole site. Our duty is to create the friendliest, performance-supporting work environment for developers\nand help non-technical people to understand the idea behind it.\nWe would like to illustrate by our example how this can be achieved.\nStage One — Measuring The Web Performance\nAt Allegro, we want to know if and how a given functionality affects the user as well as our business metrics.\nIn order to prove our hypothesis about performance impact we had to prepare a whole mechanism that allows us\nto track and analyze performance changes. I described it in greater detail in my first article titled\nMeasuring The Web Performance.\nOnly then we could start optimizing our pages. Our actions brought the expected effect — we made progress,\nbut the pace was not sufficient. We lacked the support of business people, who would see profit in all of this.\nStage Two — Make it clear that performance is important\nWe have gone to great lengths to make the entire organization realize that the gains from web performance are long-term and important overall.\nEveryone subconsciously knows that a faster site improves user experience. The earlier users are able to see a page and use it,\nthe more often they are likely to do so and return. However, we had a problem proving that it truly makes our company earn more,\nin the end this is what every business is about.\nThe first milestone turned out to be a test conducted together with the SEO team. It was an A/B test,\nwhere some users got an optimized offers list page that was loading faster, and the rest got the original page.\nIt turned out that all examined pages were added to Google cache (previously there were only a few of them),\nthe number of clicks, average ranking position and number of views increased from a few to several percent\nand the expected business profit from such a change was at 13% of the current GMV originating from organic traffic.\nAlthough being only a proof of concept, this experiment turned out to be an enabler for our next steps.\nIt helped us understand better what we were aiming for.\nThis experiment has opened the way for us to make more optimizations, it also provided us with a solid argument\nthat convinced other product teams. However, we still felt unsatisfied — if performance affects\nGMV indirectly through SEO then are we able to prove a direct correlation as well? We had plenty of data,\nbut we lacked the analytical expertise to process it, therefore, we asked our business analysts to help us.\nBased on historical performance* and business data, they were able to confirm the impact on business metrics!\nEach 100ms slowdown of First Input Delay results in an average drop in GMV of 3%.\n*The data comes from our real user measurements, not from synthetic tests.\nStage Three — Support for both business and developers\nAfter confirming our hypothesis, we had to implement a number of measures to ensure that web performance\nis taken into consideration throughout the entire process of delivery for all functionalities.\nTeaching\nOne of the main tasks of my team is to prepare the awareness campaign of our colleagues.\nTherefore, we periodically conduct two types of training:\nFor engineers, where we focus on the technical part including how to use the available tools to write optimal code.\nFor other employees (especially Product Managers), where we explain why performance is important and what benefits it brings.\nWe assume that knowledge should be shared, that is why we describe each interesting case, experiment or bug fix on our internal blog.\nThanks to that we mitigate the risk that bad patterns will be repeated in the future.\nHowever, the best way to learn is to work with us directly, so we encourage everyone to visit us as part of the\nteam tourism initiative.\nSupporting technical teams\nIn our team we believe that we should automate every task possible. We want our tools to support\nthe work of our engineers, so that they don’t have to remember to run performance tests,\ncheck the size of the resulting files, etc. That is why we have prepared several checks that apply to components development\nin our Micro Frontends architecture.\nAutomatic page scanner\nThat’s where the whole automation story started. To detect problems with assets we had to check each page manually.\nThis was neither convenient nor scalable, so we created our first bot, which used PageSpeed Insights to check if:\nassets are cached long enough,\ntheir sizes on the page are appropriate,\nthere are any assets which are not minified,\nimages are in the right format and size,\nsome images should be loaded lazily.\nAfter detecting problems, we checked the owners of the asset or part of the page and notified them on Slack.\n\nAutomatic comments in pull requests\nTwo comments are generated while building the component. The first one presents a comparison of assets size\nwith the target branch and the estimated cost of the change.\n\nIf the size exceeds the declared threshold, our entire team is automatically added as reviewers to the pull request.\nAdditionally, to detect the culprit faster, a\nWebpack Bundle Analyzer report is generated.\nIn the second one, Lighthouse reports for target and feature branches are compared in order to catch performance metrics’ regressions at this early stage.\nEach component has a list of predefined presets (input data) and a server that displays them.\nThis functionality is used for: development, visual regression, snapshot and performance testing.\nLighthouse report is generated for one or more predefined states every time the component is built.\n\nAutomatic notifications\nMy team is notified on Slack every time a new dependency is added to any of the components.\nWe want to make sure that the libraries used are optimal and have no better (smaller, faster) replacements.\n\nWe get similar notifications when assets size changes by at least 5% compared to the target branch.\nWe want to make sure that, for example, treeshaking hasn’t broken down or some other change affecting the size has not occurred.\n\nESlint\nWe use it not only for formatting but also for finding violations in our code using custom rules.\nWe have created several rules to support engineers in their daily work. You can read about a sample implementation\nin the post “Using ESLint to improve your app’s performance” on our blog.\nAnalyses\nWe get requests from other teams to analyze their components or sites. Sometimes they lack the time budget\nfor such analysis, but would like to know what to improve.\nResearch and development\nKeep in mind that working on web performance is a continuous work. Every now and then new solutions,\nwhich may have a positive impact on the loading speed, appear on the market. Therefore, together with our team,\nwe run a series of tests to see if it makes sense to adopt a given solution.\nAppreciation culture\nWe believe that the carrot is better than the stick, so we praise other teams for the achievements\nrelated to improving performance. Some time ago we used to write it down in the form of a newsletter,\nnow we talk about it during our sprint summaries.\nSummary\nWe are constantly working on data collection, monitoring, awareness raising, optimization and research,\nwhich leads to a situation where more and more managers come to us for consultation.\nThey know that performance is important and needs to be taken care of. Allegro is constantly evolving,\nnew content and features are being created, without working on performance the site will slow down.\nHowever, we already have a whole arsenal of capabilities to help us deal with this.\nWe are no longer fighting alone as the Webperf team, but as an entire organization.","guid":"https://blog.allegro.tech/2021/09/evolution-of-web-performance-culture.html","categories":["tech","webperf","frontend","performance","perfmatters","javascript"],"isoDate":"2021-09-22T22:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"How to turn on TypeScript strict mode in specific files","link":"https://blog.allegro.tech/2021/09/How-to-turn-on-TypeScript-strict-mode-in-specific-files.html","pubDate":"Mon, 06 Sep 2021 00:00:00 +0200","authors":{"author":[{"name":["Kamil Krysiak"],"photo":["https://blog.allegro.tech/img/authors/kamil.krysiak.jpg"],"url":["https://blog.allegro.tech/authors/kamil.krysiak"]},{"name":["Jarosław Glegoła"],"photo":["https://blog.allegro.tech/img/authors/jaroslaw.glegola.jpg"],"url":["https://blog.allegro.tech/authors/jaroslaw.glegola"]}]},"content":"\u003cp\u003eImagine you have to migrate your JavaScript project to TypeScript. It’s fairly simple to convert one file from JS to TS, but if\nyou want to take type checking to the next level (going for TypeScript’s strict mode) it is not that easy. The only solution you\nhave is turning on strict mode for the whole project which may result in thousands of errors. For most projects that are not strict yet,\nit would take quite a bit of time and effort to fix all the strict errors at once.\u003c/p\u003e\n\n\u003ch2 id=\"turning-strict-mode-on-in-development-only\"\u003eTurning strict-mode on in development only?\u003c/h2\u003e\n\n\u003cp\u003eYou could think of turning on strict mode during development, catching strict errors that way, and then turning it off before\npushing your changes, but this approach has a few downsides.\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003eYou’ve got to remember to change \u003ccode class=\"language-plaintext highlighter-rouge\"\u003etsconfig.json\u003c/code\u003e every time you make changes — without automation, this could get tedious.\u003c/li\u003e\n  \u003cli\u003eIt won’t work in your CI pipeline\u003c/li\u003e\n  \u003cli\u003eIt will show errors in files you don’t want to make strict yet\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eOk, so what can we do to improve this workflow?\u003c/p\u003e\n\n\u003ch2 id=\"introducing-typescript-strict-plugin\"\u003eIntroducing typescript-strict-plugin\u003c/h2\u003e\n\n\u003cp\u003e\u003ca href=\"https://github.com/allegro/typescript-strict-plugin\"\u003etypescript-strict-plugin\u003c/a\u003e eliminates all the above problems by allowing you to specify exactly what files you want to be strictly\nchecked. You can do that by simply putting a single comment at the top of the file and typescript will strictly check it. Now\nevery member of your team will have strict errors shown to them in the editor of their choosing (yes, this plugin works with\nwebstorm, vscode, vim, and more).\u003c/p\u003e\n\n\u003cp\u003eUnfortunately, typescript plugins do not work at compilation time, they work only in IDEs. Another nice feature that comes in the\npackage is a compile-time tool that allows you to connect the strict plugin to your CI pipeline, or a pre-commit hook. It checks\nmarked files with strict mode and prints to the console all strict errors found. If a single strict error is found, the tool\nexits with an error, so you can be sure that all specified files are really strict (strict, strict, strict… ahh).\u003c/p\u003e\n\n\u003ch2 id=\"how-to-use-it\"\u003eHow to use it?\u003c/h2\u003e\n\n\u003ch3 id=\"install-the-typescript-strict-plugin-package\"\u003eInstall the \u003ccode class=\"language-plaintext highlighter-rouge\"\u003etypescript-strict-plugin\u003c/code\u003e package\u003c/h3\u003e\n\n\u003cp\u003ewith npm:\u003c/p\u003e\n\n\u003cdiv class=\"language-bash highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003enpm i \u003cspan class=\"nt\"\u003e-D\u003c/span\u003e typescript-strict-plugin\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eor yarn:\u003c/p\u003e\n\n\u003cdiv class=\"language-bash highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003eyarn add \u003cspan class=\"nt\"\u003e-D\u003c/span\u003e typescript-strict-plugin\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch3 id=\"add-the-plugin-to-your-tsconfigjson\"\u003eAdd the plugin to your \u003ccode class=\"language-plaintext highlighter-rouge\"\u003etsconfig.json\u003c/code\u003e\u003c/h3\u003e\n\n\u003cdiv class=\"language-json highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n  \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"compilerOptions\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"err\"\u003e//...\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"strict\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"plugins\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"w\"\u003e\n      \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"name\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"typescript-strict-plugin\"\u003c/span\u003e\u003cspan class=\"w\"\u003e\n      \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"w\"\u003e\n  \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch3 id=\"mark-strict-files-with-ts-strict-comment\"\u003eMark strict files with \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e//@ts-strict\u003c/code\u003e comment\u003c/h3\u003e\n\n\u003cp\u003eBefore:\u003c/p\u003e\n\n\u003cdiv class=\"language-typescript highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"kd\"\u003econst\u003c/span\u003e \u003cspan class=\"nx\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"kr\"\u003estring\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003enull\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"c1\"\u003e// no error here\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eAfter:\u003c/p\u003e\n\n\u003cdiv class=\"language-typescript highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e// @ts-strict\u003c/span\u003e\n\u003cspan class=\"p\"\u003e...\u003c/span\u003e\n\u003cspan class=\"kd\"\u003econst\u003c/span\u003e \u003cspan class=\"nx\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"kr\"\u003estring\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003enull\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"c1\"\u003e// TS2322: Type ‘null’ is not assignable to type ‘string’.\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eYou can also directly specify directories you want to be strict. In the following example, every file in \u003ccode class=\"language-plaintext highlighter-rouge\"\u003esrc\u003c/code\u003e and \u003ccode class=\"language-plaintext highlighter-rouge\"\u003etest\u003c/code\u003e\ndirectories will be strictly checked.\u003c/p\u003e\n\n\u003cdiv class=\"language-json highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n  \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"compilerOptions\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"err\"\u003e//...\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"strict\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"plugins\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"w\"\u003e\n      \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"name\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"typescript-strict-plugin\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"path\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s2\"\u003e\"./src\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"./test\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"w\"\u003e\n      \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"w\"\u003e\n  \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch3 id=\"add-tsc-strict-to-your-type-checking-packagejson-scripts\"\u003eAdd \u003ccode class=\"language-plaintext highlighter-rouge\"\u003etsc-strict\u003c/code\u003e to your type checking package.json scripts\u003c/h3\u003e\n\n\u003cdiv class=\"language-json highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"err\"\u003e//\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"err\"\u003epackage.json\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n  \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"scripts\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"typecheck\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"tsc \u0026amp;\u0026amp; tsc-strict\"\u003c/span\u003e\u003cspan class=\"w\"\u003e\n  \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eOtherwise, the plugin will not work outside your IDE.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e \u003ccode class=\"language-plaintext highlighter-rouge\"\u003etsc-strict\u003c/code\u003e script uses TypeScript’s \u003ccode class=\"language-plaintext highlighter-rouge\"\u003etsc\u003c/code\u003e under the hood, so the full type checking time in this scenario would double.\u003c/p\u003e\n\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\n\u003cp\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003etypescript-strict-plugin\u003c/code\u003e can improve your app’s reliability and type safety. And all that without any disadvantages except for\ncompilation time and a few comments.\u003c/p\u003e\n\n\u003cp\u003eIf you’re interested in how this works under the hood, we are working on a separate post on making your own TS plugin, so stay\ntuned!\u003c/p\u003e\n","contentSnippet":"Imagine you have to migrate your JavaScript project to TypeScript. It’s fairly simple to convert one file from JS to TS, but if\nyou want to take type checking to the next level (going for TypeScript’s strict mode) it is not that easy. The only solution you\nhave is turning on strict mode for the whole project which may result in thousands of errors. For most projects that are not strict yet,\nit would take quite a bit of time and effort to fix all the strict errors at once.\nTurning strict-mode on in development only?\nYou could think of turning on strict mode during development, catching strict errors that way, and then turning it off before\npushing your changes, but this approach has a few downsides.\nYou’ve got to remember to change tsconfig.json every time you make changes — without automation, this could get tedious.\nIt won’t work in your CI pipeline\nIt will show errors in files you don’t want to make strict yet\nOk, so what can we do to improve this workflow?\nIntroducing typescript-strict-plugin\ntypescript-strict-plugin eliminates all the above problems by allowing you to specify exactly what files you want to be strictly\nchecked. You can do that by simply putting a single comment at the top of the file and typescript will strictly check it. Now\nevery member of your team will have strict errors shown to them in the editor of their choosing (yes, this plugin works with\nwebstorm, vscode, vim, and more).\nUnfortunately, typescript plugins do not work at compilation time, they work only in IDEs. Another nice feature that comes in the\npackage is a compile-time tool that allows you to connect the strict plugin to your CI pipeline, or a pre-commit hook. It checks\nmarked files with strict mode and prints to the console all strict errors found. If a single strict error is found, the tool\nexits with an error, so you can be sure that all specified files are really strict (strict, strict, strict… ahh).\nHow to use it?\nInstall the typescript-strict-plugin package\nwith npm:\n\nnpm i -D typescript-strict-plugin\n\n\nor yarn:\n\nyarn add -D typescript-strict-plugin\n\n\nAdd the plugin to your tsconfig.json\n\n{\n  \"compilerOptions\": {\n    //...\n    \"strict\": false,\n    \"plugins\": [\n      {\n        \"name\": \"typescript-strict-plugin\"\n      }\n    ]\n  }\n}\n\n\nMark strict files with //@ts-strict comment\nBefore:\n\nconst name: string = null; // no error here\n\n\nAfter:\n\n// @ts-strict\n...\nconst name: string = null; // TS2322: Type ‘null’ is not assignable to type ‘string’.\n\n\nYou can also directly specify directories you want to be strict. In the following example, every file in src and test\ndirectories will be strictly checked.\n\n{\n  \"compilerOptions\": {\n    //...\n    \"strict\": false,\n    \"plugins\": [\n      {\n        \"name\": \"typescript-strict-plugin\",\n        \"path\": [\"./src\", \"./test\"]\n      }\n    ]\n  }\n}\n\n\nAdd tsc-strict to your type checking package.json scripts\n\n// package.json\n{\n  \"scripts\": {\n    \"typecheck\": \"tsc \u0026\u0026 tsc-strict\"\n  }\n}\n\n\nOtherwise, the plugin will not work outside your IDE.\nNote: tsc-strict script uses TypeScript’s tsc under the hood, so the full type checking time in this scenario would double.\nConclusion\ntypescript-strict-plugin can improve your app’s reliability and type safety. And all that without any disadvantages except for\ncompilation time and a few comments.\nIf you’re interested in how this works under the hood, we are working on a separate post on making your own TS plugin, so stay\ntuned!","guid":"https://blog.allegro.tech/2021/09/How-to-turn-on-TypeScript-strict-mode-in-specific-files.html","categories":["typescript","scrict mode","typescript plugin","code quality"],"isoDate":"2021-09-05T22:00:00.000Z","thumbnail":"images/post-headers/default.jpg"}],"jobs":[{"id":"743999778992282","name":"Research Engineer - Machine Learning","uuid":"6f1d000a-5d57-4657-b010-e74a5e9e281e","refNumber":"REF1694Q","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-10-12T11:51:53.000Z","location":{"city":"Warszawa, Kraków, Poznań, Toruń, Wrocław","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"31873284-1e97-427d-8918-6ce504344351","valueLabel":"Nie"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"data scientist, NLP, ML, uczenie maszynowe, sieci neuronowe, modele lasów drzew decyzyjnych, modele Bayes’owskie, information retrieval, język naturalny, szeregi czasowe, dane, python, statystyka"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999778992282","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}},{"id":"743999777750483","name":"Research Engineer - Machine Learning (Ranking and Recommendations)","uuid":"7b2ee40a-d794-462e-bf21-4059c8fbfc82","refNumber":"REF2990T","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-10-05T18:38:21.000Z","location":{"city":"Warszawa, Poznań, Kraków, Toruń, Wrocław","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"60cb31a9c87e511299a3a050","fieldLabel":"Department II","valueId":"b8a4596e-d9ce-42bb-8de5-10995e9ccf99","valueLabel":"IT - Machine Learning"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"ML, AI, Ranking, Research, Machine Learning"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999777750483","creator":{"name":"Mateusz Jabłonowski"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}},{"id":"743999777595922","name":"Research Engineer - Machine Learning (Reinforcement Learning)","uuid":"b333619c-818c-45f4-9f79-1f3d48d8e204","refNumber":"REF2881V","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-10-05T07:34:28.000Z","location":{"city":"Warszawa, Kraków, Poznań, Toruń","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"ML, Machine Learning, Python, Deep Learning, AI, Artificial Intelligence"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999777595922","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}},{"id":"743999777595727","name":"Research Engineer - Machine Learning (Computer Vision)","uuid":"56f2b270-0d68-4d17-80ce-4bcba732b9ce","refNumber":"REF2880R","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-10-05T07:33:43.000Z","location":{"city":"Warszawa, Kraków, Poznań, Toruń","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999777595727","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}},{"id":"743999777595496","name":"Data Scientist (Allegro Pay)","uuid":"5fb5b029-2869-48a0-9136-2123e0d48f2e","refNumber":"REF1962X","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-10-05T07:32:36.000Z","location":{"city":"Warszawa","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"fa9e2c82-b44f-40df-a699-4dea59cb0c13","valueLabel":"Nie"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"9c8396d4-11a6-443c-897c-15f29221a3fd","valueLabel":"Allegro Pay sp. z o.o."},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"python, ml, machine learning, ds, algorytm, uczenie maszynowe, sceince, data science, data, forecasting, credit scoring, płatności, pay"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999777595496","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}}],"papers":[{"authors":"Konrad Czechowski, Tomasz Odrzygóźdź, Marek Zbysiński, Michał Zawalski, Krzysztof Olejnik, Yuhuai Wu, Łukasz Kuciński, Piotr Miłoś","date":"2021","paper_url":"https://arxiv.org/abs/2108.11204","accepted_at":"Conference and Workshop on Neural Information Processing Systems (NeurIPS)","paper_title":"Subgoal Search For Complex Reasoning Tasks"},{"authors":"Robert Mroczkowski, Piotr Rybak, Alina Wróblewska, Ireneusz Gawlik","date":"2021","paper_url":"https://www.aclweb.org/anthology/2021.bsnlp-1.1/","accepted_at":"BSNLP, accepted long paper","paper_title":"HerBERT: Efficiently Pretrained Transformer-based Language Model for Polish"},{"authors":"Piotr Rybak, Robert Mroczkowski, Janusz Tracz, Ireneusz Gawlik","date":"2020","paper_url":"https://www.aclweb.org/anthology/2020.acl-main.111/","accepted_at":"ACL 2020, accepted long paper","paper_title":"KLEJ: Comprehensive Benchmark for Polish Language Understanding"},{"authors":"Przemysław Pobrotyn, Tomasz Bartczak, Mikołaj Synowiec, Radosław Białobrzeski, Jarosław Bojar","date":"2020","paper_url":"https://arxiv.org/abs/2005.10084","accepted_at":"SIGIR eCommerce Workshop 2020, contributed talk","paper_title":"Context-Aware Learning to Rank with Self-Attention"},{"authors":"Przemysław Pobrotyn, Radosław Białobrzeski","date":"2020","paper_url":"https://arxiv.org/abs/2102.07831","accepted_at":"The 2021 SIGIR Workshop On eCommerce (SIGIR eCom ’21)","paper_title":"NeuralNDCG: Direct Optimisation of a Ranking Metric via Differentiable Relaxation of Sorting"},{"authors":"Janusz Tracz, Piotr Wójcik, Kalina Jasinska-Kobus, Riccardo Belluzzo, Robert Mroczkowski, Ireneusz Gawlik","date":"2020","paper_url":"https://www.aclweb.org/anthology/2020.ecomnlp-1.7/","accepted_at":"EComNLP 2020 COLING Workshop on Natural Language Processing in E-Commerce","paper_title":"BERT-based similarity learning for product matching"}],"videos":[{"title":"Polacy nie gęsi, iż swojego BERTa mają","url":"https://vimeo.com/471413175","who":"Piotr Rybak","description":"An introduction to our HerBERT model. Presentation at https://www.nlpday.pl/","thumb":"images/video-headers/polacy_nie_gesi.png"},{"title":"Jak skutecznie zarządzać projektami uczenia maszynowego?","url":"https://www.youtube.com/watch?v=gWDSdJfP7gU","who":"Ireneusz Gawlik","description":"Presentation at https://ghostday.pl/","thumb":"images/video-headers/irek_gawlik_mgmt.png"},{"title":"What does the user ask for? - Discovering new intents in conversational data","url":"https://www.youtube.com/watch?v=vSSZ3ANyVb0","who":"Piotr Rybak","description":"Presentation at https://ghostday.pl/index.php/speakers/#talk-613","thumb":"images/video-headers/p.rybak_intencje.png"},{"title":"Challenges of commercializing language models on mobile devices","url":"https://www.youtube.com/watch?v=tC3yNlPg_Bw","who":"Szymon Łęski","description":"Presentation at https://ghostday.pl/index.php/speakers/#talk-664","thumb":"images/video-headers/sz.lecki_prod.png"}],"videos2":[{"title":"Batch construction strategies in deep metric learning","url":"https://www.youtube.com/watch?v=wsBLHArYFtM","who":"Bartosz Ludwiczuk \u0026 Kalina Kobus","description":"Presentation at https://ghostday.pl/index.php/speakers/#talk-615","thumb":"images/video-headers/kalina_batch_const.png"},{"title":"(Many shades of) ML @ Allegro.pl: NLP, Vision \u0026 ranking at the largest Polish e-commerce marketplace","url":"https://www.youtube.com/watch?v=hXGSxTNVmwg","who":"Przemysław Pobrotyn","description":"Presentation at https://ghostday.pl/index.php/speakers/#talk-706","thumb":"images/video-headers/przemoc_many_shades.png"},{"title":"Machine learning i przyszłość algorytmów","url":"https://www.youtube.com/watch?v=UT3bGUEY-8o","who":"Ireneusz Gawlik","description":"Presentation at [Copernicus Festival](https://copernicusfestival.com/event/machine-learning-i-przyszlosc-algorytmow-czy-sztuczna-inteligencja-moze-zrozumiec-zachowania-konsumentow/)","thumb":"images/video-headers/irek.gawlik_copernicus.png"},{"title":"Badania i rozwój ML w Allegro","url":"https://allegro.tech/podcast/badania_i_rozwoj_ml_w_allegro/","who":"Ireneusz Gawlik","description":"Allegro.tech podcast","thumb":"images/video-headers/irek.gawlik_podcast.png"}],"open_source":[{"name":"allRank","url":"https://github.com/allegro/allRank","description":"framework for training neural Learning-to-Rank (LTR) models,\nfeaturing implementations of:\n*  common pointwise, pairwise and listwise loss function,\n* fully connected and Transformer-like scoring function,\n* commonly used evaluation metrics like Normalized Discounted Cumulative Gain (NDCG) and Mean Reciprocal Rank (MRR},\n* click-models for experiments on simulated click-through data"},{"name":"KLEJ Benchmark","url":"https://klejbenchmark.com/","icon":"FaTint","description":"The KLEJ benchmark (Kompleksowa Lista Ewaluacji Językowych) is a set of nine evaluation tasks for the Polish language understanding. Key benchmark features:\n* It contains a diverse set of tasks from different domains and with different objectives,\n* Most tasks are created from existing datasets but we also release the new sentiment analysis dataset from an e-commerce domain."},{"name":"HerBERT","url":"https://huggingface.co/allegro","description":"HerBERT is a BERT-based language model trained on six different corpora for Polish language understanding. It achieves state-of-the-art results on multiple downstream tasks, including [KLEJ Benchmark](https://klejbenchmark.com/) and Part-of-Speech tagging. We release both Base and Large variants of the model as a part of [transformers](https://github.com/huggingface/transformers) library for anyone to use."}],"teams":[{"name":"CX Robots","icon":"FaRobot","description":"We focus on using NLP models to understand and automate the communication at Allegro, e.g. automatically answer questions asked to our customer support. Our main research directions are related to pretraining and evaluating large language models, semi-supervised clustering, and human-in-the-loop NLP."},{"name":"Learning to Rank","icon":"FaList","description":"In Learning to Rank, our goal is to develop ranking models which find the optimal ordering of items for a given search results list, based on past users’ interactions. Such models constitute the final stage of Allegro’s search engine, serving millions of searches a day.\n\nSome of the research problems we tackle are:\n1. Incorporation of multimodal data (textual, visual, tabular) into an end-to-end ranking model.\n1. Search engine personalization\n1. Developing novel ranking architectures and loss functions"},{"name":"Visual Search","icon":"FaImages","description":"In Visual Search, we create machine learning models which enable us to create image embeddings suitable for similarity search. The main challenge is to make these embeddings sensitive to relevant visual traits of products like category, style, colour, pattern etc. while maintaining insensitivity to irrelevant information such as background, presence of a model, different camera angles etc."},{"name":"PCS Automation","icon":"FaShoppingBag","description":"We employ a diverse set of machine learning techniques to improve the product-based experience on Allegro. Problems that we solve include, e.g., product matching i.e., being able to infer the product being sold for a merchant-created offer, or automatic integration of product definitions from external product catalogs. Examples of our research directions include sampling methods in similarity learning or extreme classification methods."},{"name":"Recommendations","icon":"FaSitemap","description":"The main purpose of our team is to address users’ needs, show them a broad range of products they would be interested in - thus serving as an inspiration and connecting them with useful, contextual offers.\nWe ground our algorithms on previous collective behaviors of our user-base. But we also work towards incorporating content features of the items into the models. Our main challenges include building novel algorithms that can give good recommendations for our users and also operate at scale. Both being a significant endeavour, considering the sheer amount of traffic Allegro serves daily.\n\nWe focus our research on:\n1. Building item representation, that can serve as retrieval basis,\n1. Improving ways to detect user intents in clear (and useful) way,\n1. Current trends in recommender systems."},{"name":"Reinforcement Learning","icon":"FaSignal","description":"We aim to enhance various Allegro projects with exploratory algorithms, which are capable to not only exploit historical data but explore via interactions with the world. Currently, we are working on the optimization of Search Engine Marketing (SEM) and Content Optimization projects. Our main research directions include contextual bandits, A/B testing alternatives with casual impact discovery and offline RL. "}]},"__N_SSG":true},"page":"/","query":{},"buildId":"R-ClZbbDZqAFy-9C_TSri","isFallback":false,"gsp":true}</script><script nomodule="" src="/_next/static/chunks/polyfills-eef578260fd80f8fff94.js"></script><script src="/_next/static/chunks/webpack-af8d060cb140570bcfb2.js" async=""></script><script src="/_next/static/chunks/framework-0441fae7fd130f37dee1.js" async=""></script><script src="/_next/static/chunks/main-547dee26f92077ae29b6.js" async=""></script><script src="/_next/static/chunks/pages/_app-789ec92d9bd7cfd0c310.js" async=""></script><script src="/_next/static/chunks/1bfc9850-b36c3444c0662e0df878.js" async=""></script><script src="/_next/static/chunks/111-1b6a593163529b0806ae.js" async=""></script><script src="/_next/static/chunks/pages/index-9a2b191d0eeeadf48ff5.js" async=""></script><script src="/_next/static/R-ClZbbDZqAFy-9C_TSri/_buildManifest.js" async=""></script><script src="/_next/static/R-ClZbbDZqAFy-9C_TSri/_ssgManifest.js" async=""></script></body></html>